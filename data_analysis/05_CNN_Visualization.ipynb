{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from helperFunctions import *\n",
    "from constants import *\n",
    "from dataAnalysisFunctions import getSEM, getCleanedSignal, getIntervals, getPowerRatio\n",
    "import pandas as pd\n",
    "\n",
    "from featureBuilder import featureBuilder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "model = torch.load(\"models/model_t_combined_trimmed_filtered_3class.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataframes and variables needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datas and concat into one dataframe \n",
    "# Load dataset 1\n",
    "foldername='P001'\n",
    "filename='part_P001_block_S004'\n",
    "#filtered_data = loadData(datatype='filtered_data', foldername=foldername, filename=filename)\n",
    "#filtered_cleaned_data = loadData(datatype='filtered_cleaned_data', foldername=foldername, filename=filename)\n",
    "df1 = loadData(datatype='dataframe', foldername=foldername, filename=filename)\n",
    "\n",
    "# Load dataset 2\n",
    "foldername='P001'\n",
    "filename='part_P001_block_S005'\n",
    "df2 = loadData(datatype='dataframe', foldername=foldername, filename=filename)\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focused len: 420 unfocused len: 420\n"
     ]
    }
   ],
   "source": [
    "# Select the trials needed to classify\n",
    "focused_state = df[\"trial_time\"] == 0.7\n",
    "unfocused_state = df[\"trial_time\"] > 0.9\n",
    "\n",
    "focused_df = df[focused_state]\n",
    "unfocused_df = df[unfocused_state]\n",
    "\n",
    "num_to_keep = min(len(focused_df), len(unfocused_df))\n",
    "\n",
    "focused_df = focused_df.drop(focused_df.sample(len(focused_df) - num_to_keep).index)\n",
    "unfocused_df = unfocused_df.drop(unfocused_df.sample(len(unfocused_df) - num_to_keep).index)\n",
    "\n",
    "print(\"focused len:\", len(focused_df), \"unfocused len:\", len(unfocused_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dataframes\n",
    "fb = featureBuilder()\n",
    "dictionary = {}\n",
    "for row_index,row in focused_df.iterrows():\n",
    "    dictionary = fb.appendDataToDict(row[\"data_extended\"], focused=2, dictionary=dictionary)\n",
    "for row_index,row in unfocused_df.iterrows():\n",
    "    dictionary = fb.appendDataToDict(row[\"data_extended\"], focused=0, dictionary=dictionary)\n",
    "# for row_index,row in med_df.iterrows():\n",
    "#     dictionary = fb.appendDataToDict(row[\"data_extended\"], focused=1, dictionary=dictionary)\n",
    "\n",
    "feature_df = pd.DataFrame(dictionary)\n",
    "len(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for visualizing LDA components\n",
    "colors=['blue', 'orange', 'green']\n",
    "class_names=[\"unfocused\", \"mid_focused\", \"focused\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA using sklearn 1 dim (2 possible outputs)\n",
    "https://stackabuse.com/implementing-lda-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6547619047619048\n",
      "Accuracy 0.7321428571428571\n",
      "Accuracy 0.6845238095238095\n",
      "Accuracy 0.6369047619047619\n",
      "Accuracy 0.6488095238095238\n",
      "Accuracy 0.6369047619047619\n",
      "Accuracy 0.6428571428571429\n",
      "Accuracy 0.625\n",
      "Accuracy 0.7023809523809523\n",
      "Accuracy 0.6488095238095238\n",
      "Avg LDA + Random Forest accuracy: 0.6613095238095237\n"
     ]
    }
   ],
   "source": [
    "# Average the accuracy over X different random samples\n",
    "accuracies = []\n",
    "for rand_state_var in range(10): \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_df.drop(columns=[\"focused\"]), feature_df[\"focused\"], test_size=0.2, random_state=rand_state_var)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "    features_wo_output = feature_df.drop(columns=[\"focused\"])\n",
    "    X_train, scaler = scaleData(X_train, X_train.columns.values) # Scaling doesn't change anything\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_train = lda.fit_transform(X_train, y_train)\n",
    "    X_test = lda.transform(X_test)\n",
    "\n",
    "\n",
    "    ## Classify using random forest classifier\n",
    "    classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Report accuracy\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    #print(cm)\n",
    "    print('Accuracy', str(accuracy_score(y_test, y_pred)))\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "print(\"Avg LDA + Random Forest accuracy:\", np.mean(np.array(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA w/ SVM Classifier\n",
    "https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6428571428571429\n",
      "Accuracy 0.7023809523809523\n",
      "Accuracy 0.6785714285714286\n",
      "Accuracy 0.6547619047619048\n",
      "Accuracy 0.6547619047619048\n",
      "Accuracy 0.6130952380952381\n",
      "Accuracy 0.6488095238095238\n",
      "Accuracy 0.6071428571428571\n",
      "Accuracy 0.7321428571428571\n",
      "Accuracy 0.6190476190476191\n",
      "Avg LDA + SVM accuracy: 0.6553571428571429\n"
     ]
    }
   ],
   "source": [
    "# Average the accuracy over X different random samples\n",
    "accuracies = []\n",
    "for rand_state_var in range(10): \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_df.drop(columns=[\"focused\"]), feature_df[\"focused\"], test_size=0.2, random_state=rand_state_var)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "    features_wo_output = feature_df.drop(columns=[\"focused\"])\n",
    "    X_train, scaler = scaleData(X_train, X_train.columns.values) # Scaling doesn't change anything\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_train = lda.fit_transform(X_train, y_train)\n",
    "    X_test = lda.transform(X_test)\n",
    "\n",
    "\n",
    "    ## Classify using SVM\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Report accuracy\n",
    "    #cm = confusion_matrix(y_test, y_pred)\n",
    "    #print(cm)\n",
    "    print('Accuracy', str(accuracy_score(y_test, y_pred)))\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "print(\"Avg LDA + SVM accuracy:\", np.mean(np.array(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-105.31801068131631, 'average norm_mean_first_difference'),\n",
       " (-61.562905540978235, 'right norm_mean_second_difference'),\n",
       " (-43.0219075725154, 'left norm_mean_second_difference'),\n",
       " (-15.88800525186798, 'left std_voltage'),\n",
       " (-14.499482820332535, 'right std_voltage'),\n",
       " (-9.642850611865999, 'left_minus_right mean_second_difference'),\n",
       " (-9.194611541857569, 'left mean_second_difference'),\n",
       " (-7.655101986878625, 'beta average'),\n",
       " (-6.459399420311664, 'average mean_second_difference'),\n",
       " (-4.445081686787261, 'alpha average_power'),\n",
       " (-4.281657380010008, 'alpha left'),\n",
       " (-3.6163625729181206, 'alpha right'),\n",
       " (-2.266209211900748, 'right mean_second_difference'),\n",
       " (-2.2131109379150136, 'delta average'),\n",
       " (-2.152359798036299, 'beta left_minus_right'),\n",
       " (-1.7945167603092536, 'theta left'),\n",
       " (-1.6378760883933294, 'theta average_power'),\n",
       " (-1.5493752970840868, 'alpha left_minus_right_power'),\n",
       " (-1.0498121293209908, 'left_minus_right norm_mean_second_difference'),\n",
       " (-1.0481574768808049, 'theta right'),\n",
       " (-0.9496888483202923, 'theta left_minus_right_power'),\n",
       " (-0.48273519517709007, 'theta left_minus_right'),\n",
       " (-0.31983293463798124, 'delta left_minus_right_power'),\n",
       " (0.23391987591069124, 'delta left'),\n",
       " (0.283336171971917, 'right average_voltage'),\n",
       " (0.33117822777540873, 'alpha/beta left'),\n",
       " (0.33117822777555594, 'alpha/beta right'),\n",
       " (0.3311782277755705, 'alpha/beta left_minus_right'),\n",
       " (0.33117822777559836, 'alpha/beta average'),\n",
       " (0.35798606163599045, 'delta average_power'),\n",
       " (0.3950369615332592, 'delta right'),\n",
       " (0.5626484828106837, 'theta/alpha left'),\n",
       " (0.5626484828107672, 'theta/alpha right'),\n",
       " (0.5626484828108276, 'theta/alpha average'),\n",
       " (0.5626484828108276, 'theta/alpha left_minus_right'),\n",
       " (0.5646265487591713, 'delta/beta left_minus_right'),\n",
       " (0.5646265487593156, 'delta/beta right'),\n",
       " (0.5646265487595725, 'delta/beta average'),\n",
       " (0.5646265487598339, 'delta/beta left'),\n",
       " (0.6859077093868579, 'theta average'),\n",
       " (0.6923471488503983, 'average average_voltage'),\n",
       " (0.9163699323322232, 'left_minus_right std_voltage'),\n",
       " (1.0199297115243666, 'left average_voltage'),\n",
       " (1.1268605735716664, 'theta/beta left'),\n",
       " (1.1268605735719837, 'theta/beta right'),\n",
       " (1.12686057357258, 'theta/beta left_minus_right'),\n",
       " (1.1268605735729937, 'theta/beta average'),\n",
       " (1.7624920415996859, 'left_minus_right norm_mean_first_difference'),\n",
       " (1.8627443627856572, 'left_minus_right average_voltage'),\n",
       " (1.905600089742951, 'right mean_first_difference'),\n",
       " (2.1267476670162346, 'delta left_minus_right'),\n",
       " (2.2202454991886738, 'beta left_minus_right_power'),\n",
       " (2.695340317413886, 'alpha left_minus_right'),\n",
       " (2.9177728876493045, 'beta right'),\n",
       " (3.942664641975724, 'beta average_power'),\n",
       " (4.186383196696543, 'beta left'),\n",
       " (6.704693686079354, 'average mean_first_difference'),\n",
       " (9.971013273058013, 'alpha average'),\n",
       " (10.072718576423622, 'left mean_first_difference'),\n",
       " (10.85309941494237, 'left_minus_right mean_first_difference'),\n",
       " (16.860121114354833, 'average std_voltage'),\n",
       " (44.51314376613373, 'left norm_mean_first_difference'),\n",
       " (70.28191651693481, 'right norm_mean_first_difference'),\n",
       " (93.08762295075377, 'average norm_mean_second_difference')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_list = list(zip(lda.coef_[0], feature_df.drop(columns=\"focused\").columns))\n",
    "sorted_zip_list = sorted(zipped_list)\n",
    "sorted_zip_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA explained variance: [1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize LDA model \n",
    "print(\"LDA explained variance:\", lda.explained_variance_ratio_)\n",
    "\n",
    "# Create dataframe for the feature\n",
    "lda_feature_df = pd.DataFrame(X_train, columns=['LDA 1'])\n",
    "lda_feature_df['focused']=y_train.values\n",
    "\n",
    "# Plot groups wrt LDA 1 dimension\n",
    "\n",
    "for class_name, df in lda_feature_df.groupby('focused'): \n",
    "    plt.hist(df['LDA 1'].values, alpha=0.5, label=class_name)\n",
    "\n",
    "plt.xlabel('LD1')\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Distribution of unfocused (0) vs focused (2)\")    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_feature_means = pd.DataFrame(columns=[False,True])\n",
    "for class_name, rows in feature_df.groupby('focused'):\n",
    "    class_feature_means[class_name] = rows.mean()\n",
    "    \n",
    "class_feature_means = class_feature_means.drop(['focused'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(class_feature_means)\n",
    "within_class_scatter_matrix = np.zeros((num_features, num_features))\n",
    "for c,rows in feature_df.groupby('focused'):\n",
    "    rows=rows.drop(columns=['focused'])\n",
    "    s = np.zeros((num_features, num_features))\n",
    "    for index, row in rows.iterrows():\n",
    "        x, mc = row.values.reshape(num_features, 1), class_feature_means[c].values.reshape(num_features, 1)\n",
    "        s += (x-mc).dot((x-mc).T)\n",
    "    within_class_scatter_matrix += s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_means = feature_df.mean().drop(['focused'])\n",
    "between_class_scatter_matrix = np.zeros((num_features, num_features))\n",
    "for c,rows in feature_df.groupby('focused'):\n",
    "    rows=rows.drop(columns=['focused'])\n",
    "    n = len(rows)\n",
    "    mc, m = class_feature_means[c].values.reshape(num_features, 1), feature_means.values.reshape(num_features, 1)\n",
    "    between_class_scatter_matrix += n*(mc - m).dot((mc - m).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_class_scatter_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_class_scatter_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_within_class_scatter_matrix = np.linalg.pinv(within_class_scatter_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_values, eigen_vectors = np.linalg.eig(inv_within_class_scatter_matrix.dot(between_class_scatter_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(np.abs(eigen_values[i]), eigen_vectors[:,i]) for i in range(len(eigen_values))]\n",
    "pairs = sorted(pairs, key=lambda x: x[0], reverse=True)\n",
    "print(\"top 10 eigenvalues\")\n",
    "for pair in pairs[:10]:\n",
    "    print(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_matrix = np.hstack((pairs[0][1].reshape(num_features,1), pairs[1][1].reshape(num_features,1))).real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_value_sums = sum(eigen_values)\n",
    "print('Explained Variance')\n",
    "for i, pair in enumerate(pairs):\n",
    "    print('Eigenvector {}: {}'.format(i, (pair[0]/eigen_value_sums).real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lda = np.array(feature_df.drop(columns=['focused']).dot(w_matrix))\n",
    "X_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(feature_df['focused'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('LD1')\n",
    "plt.scatter(\n",
    "    X_lda[:,0],\n",
    "    y,\n",
    "    c=y,\n",
    "    cmap='rainbow',\n",
    "    alpha=0.7,\n",
    "    edgecolors='b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
