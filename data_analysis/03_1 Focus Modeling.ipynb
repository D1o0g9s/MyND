{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyND Offline Processing: Data Analysis\n",
    "Author: Geeling Chau<br> \n",
    "<br>\n",
    "Description: Visualize power bin features<br>\n",
    "Sources: \n",
    "- Ollie's Segment Speller Offline Processing Code https://github.com/ollie-d/SegSpeller/blob/master/Offline%20Processing.ipynb \n",
    "- neurodsp https://github.com/neurodsp-tools/neurodsp\n",
    "- FOOOF https://fooof-tools.github.io/fooof/index.html \n",
    "- PyEEG http://pyeeg.sourceforge.net/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helperFunctions import *\n",
    "from constants import *\n",
    "from dataAnalysisFunctions import *\n",
    "\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "from neurodsp.plts.spectral import *\n",
    "\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binning interval\n",
    "binning=[4, 7, 12, 30]\n",
    "intervals = getIntervals(binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPowerRatioAvgSEM(eeg_list, num_eeg_timepoints=499, binning=binning): \n",
    "    power_ratio = [getPowerRatio(data[:num_eeg_timepoints], binning) for data in eeg_list]\n",
    "    return np.mean(power_ratio, axis=0), getSEM(power_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P001 part_P001_block_S004\n"
     ]
    }
   ],
   "source": [
    "# Load data frame and filtered_cleaned_data\n",
    "# Also initialize the path and directories\n",
    "\n",
    "filename_foldername_dict_path = \"../data/most_currently_updated.pickle\"\n",
    "filename_foldername_dict = loadPickle(filename_foldername_dict_path)\n",
    "\n",
    "foldername='P008'#filename_foldername_dict[\"foldername\"]\n",
    "filename='expP008_block_short'#filename_foldername_dict[\"filename\"]\n",
    "print(foldername, filename)\n",
    "\n",
    "article_results_directory = \"../data/article_results/\"+foldername+\"/\"\n",
    "article_results_path = article_results_directory+filename+\".pickle\"\n",
    "\n",
    "article_results_sem_directory = \"../data/article_sem_results/\"+foldername+\"/\"\n",
    "article_results_sem_path = article_results_sem_directory+filename+\".pickle\"\n",
    "\n",
    "dataframe_directory = \"../data/dataframe/\"+foldername+\"/\"\n",
    "dataframe_path = dataframe_directory+filename+\".pickle\"\n",
    "\n",
    "unfocused_states_df_directory = \"../data/unfocused_states_df/\"+foldername+\"/\"\n",
    "unfocused_states_df_path = unfocused_states_df_directory+filename+\".pickle\"\n",
    "\n",
    "ustatistic_directory = \"../data/ustatistic/\"+foldername+\"/\"\n",
    "ustatistic_path = ustatistic_directory+filename+\".pickle\"\n",
    "\n",
    "pvalue_directory = \"../data/pvalue/\"+foldername+\"/\"\n",
    "pvalue_path = pvalue_directory+filename+\".pickle\"\n",
    "\n",
    "\n",
    "df = loadPickle(dataframe_path)\n",
    "\n",
    "incorporate_matlab_data = False\n",
    "if incorporate_matlab_data: \n",
    "    filtered_matlab_data_directory = \"../data/filtered_matlab_data/\"+foldername+\"/\"\n",
    "    filtered_matlab_data_path = filtered_matlab_data_directory+filename+\".pickle\"\n",
    "    filtered_matlab_data = loadPickle(filtered_matlab_data_path)\n",
    "    all_data = filtered_matlab_data\n",
    "    data_type = \"data_matlab\"\n",
    "else :\n",
    "    filtered_cleaned_data_directory = \"../data/filtered_cleaned_data/\"+foldername+\"/\"\n",
    "    filtered_cleaned_data_path = filtered_cleaned_data_directory+filename+\".pickle\"\n",
    "    filtered_cleaned_data = loadPickle(filtered_cleaned_data_path)\n",
    "    all_data = filtered_cleaned_data\n",
    "    data_type= \"data\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeBalanced(df1, df2, window_size=10) :\n",
    "    # Returns data frames that contain equal number of elements from df1 and df2 and has them be in the nearest time intervals\n",
    "    start_1 = df1.iloc[0][\"data_index\"]\n",
    "    start_2 = df2.iloc[0][\"data_index\"]\n",
    "    # Find minimum of the two starting indexes\n",
    "    min_ind = start_1 if start_1 < start_2 else start_2\n",
    "    max_ind = min_ind + window_size\n",
    "    \n",
    "    df1_to_return_indexes = list()\n",
    "    df2_to_return_indexes = list()\n",
    "    \n",
    "    df1_copy = df1.copy()\n",
    "    df2_copy = df2.copy()\n",
    "    max_data_index = max(df1[\"data_index\"]) if max(df1[\"data_index\"]) > max(df2[\"data_index\"]) else max(df2[\"data_index\"])\n",
    "    # print(max_data_index)\n",
    "    while min_ind < max_data_index : \n",
    "        # get sublists\n",
    "        sub_df1 = df1_copy[(df1_copy[\"data_index\"] >= min_ind) & (df1_copy[\"data_index\"] < max_ind)]\n",
    "        sub_df2 = df2_copy[(df2_copy[\"data_index\"] >= min_ind) & (df2_copy[\"data_index\"] < max_ind)]\n",
    "\n",
    "        # if any of the sub lists are empty, increment min index\n",
    "        if (len(sub_df1) == 0) or (len(sub_df2) == 0): \n",
    "            min_ind += 1\n",
    "        else :\n",
    "            # Otherwise, continue poping from both lists until one is empty, by which you increase min_index to after the numbers just added\n",
    "            df1_to_add = sub_df1.iloc[0][\"data_index\"]\n",
    "            df2_to_add = sub_df2.iloc[0][\"data_index\"]\n",
    "            while not((len(sub_df1) == 0) or (len(sub_df2) == 0)): \n",
    "                df1_to_add = sub_df1.iloc[0][\"data_index\"]\n",
    "                df2_to_add = sub_df2.iloc[0][\"data_index\"]\n",
    "\n",
    "                df1_to_return_indexes.append(df1_to_add)\n",
    "                df2_to_return_indexes.append(df2_to_add)\n",
    "\n",
    "                sub_df1 = sub_df1[sub_df1[\"data_index\"] != df1_to_add]\n",
    "                sub_df2 = sub_df2[sub_df2[\"data_index\"] != df2_to_add]\n",
    "                df1_copy = df1_copy[df1_copy[\"data_index\"] != df1_to_add]\n",
    "                df2_copy = df2_copy[df2_copy[\"data_index\"] != df2_to_add]\n",
    "\n",
    "            min_ind += 1\n",
    "\n",
    "        max_ind = min_ind + window_size\n",
    "    # print(df1_to_return_indexes)\n",
    "    return df1[df1[\"data_index\"].isin(df1_to_return_indexes)], df2[df2[\"data_index\"].isin(df2_to_return_indexes)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFocusedPeriods(unfocused_state, num_trials_wide=10):\n",
    "    # Don't need this, but it basically flips the selection to select for focus periods instead of unfocus\n",
    "    focus_indexes = set()\n",
    "    prev_cursor = 0\n",
    "    for i, state in enumerate(unfocused_state) :\n",
    "        if state: \n",
    "            prev_cursor = i+1 \n",
    "        else :\n",
    "            if i - prev_cursor > num_trials_wide: \n",
    "                # Add the middle of the focus period to the focus_indexes\n",
    "                focus_indexes.add(prev_cursor + (num_trials_wide // 2)) \n",
    "                prev_cursor = i\n",
    "    \n",
    "    to_return = [False] * len(unfocused_state)\n",
    "    for i, state in enumerate(unfocused_state) :\n",
    "        if i in focus_indexes :\n",
    "            to_return[i] = True\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4a3700305ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;31m# unfocused_state = getSmoothedPerformance(unfocused_state, num_before, num_after)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mfocused_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSmoothedPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_article\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trial_time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_after\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfocused_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timepoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UCSD/RESEARCH/NeuroFocus/Mynd/Data Analysis/helperFunctions.py\u001b[0m in \u001b[0;36mgetSmoothedPerformance\u001b[0;34m(original_performance, num_ahead, num_behind)\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0moriginal_performance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0mto_return\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mne/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Get the focus vs unfocus of alpha vs theta vs beta\n",
    "\n",
    "\n",
    "\n",
    "# Get sections\n",
    "numSections = getNumSections(filtered_cleaned_data)\n",
    "\n",
    "\n",
    "if not os.path.isfile(pvalue_path):\n",
    "\n",
    "    article_results = {}\n",
    "    article_sem_results = {}\n",
    "    unfocused_states = {}\n",
    "    unfocused_states[\"timepoint\"] = list()\n",
    "    unfocused_states[\"article_num_before_after\"] = list()\n",
    "    unfocused_states[\"unfocused_times\"] = list()\n",
    "\n",
    "    mann_whitney_pvalue_results = {}\n",
    "    mann_whitney_ustatistic_results = {}\n",
    "\n",
    "    for article in range(1, numSections+1):\n",
    "#         if article == 2:\n",
    "#             continue # do not include the second article for P008 Long\n",
    "        df_article = df[df[\"section_number\"] == article]\n",
    "\n",
    "        article_results[article] = {}\n",
    "        article_results[article][\"focus\"] = {}\n",
    "        article_results[article][\"focus\"][\"alpha\"] = list()\n",
    "        article_results[article][\"focus\"][\"theta\"] = list()\n",
    "        article_results[article][\"focus\"][\"beta\"] = list()\n",
    "\n",
    "        article_results[article][\"unfocus\"] = {}\n",
    "        article_results[article][\"unfocus\"][\"alpha\"] = list()\n",
    "        article_results[article][\"unfocus\"][\"theta\"] = list()\n",
    "        article_results[article][\"unfocus\"][\"beta\"] = list()\n",
    "\n",
    "\n",
    "        article_sem_results[article] = {}\n",
    "        article_sem_results[article][\"focus\"] = {}\n",
    "        article_sem_results[article][\"focus\"][\"alpha\"] = list()\n",
    "        article_sem_results[article][\"focus\"][\"theta\"] = list()\n",
    "        article_sem_results[article][\"focus\"][\"beta\"] = list()\n",
    "\n",
    "        article_sem_results[article][\"unfocus\"] = {}\n",
    "        article_sem_results[article][\"unfocus\"][\"alpha\"] = list()\n",
    "        article_sem_results[article][\"unfocus\"][\"theta\"] = list()\n",
    "        article_sem_results[article][\"unfocus\"][\"beta\"] = list()\n",
    "        \n",
    "        \n",
    "        mann_whitney_pvalue_results[article] = list()\n",
    "        mann_whitney_ustatistic_results[article] = list()\n",
    "        \n",
    "        for i in range(len(intervals)) :\n",
    "            mann_whitney_pvalue_results[article].append(list())\n",
    "            mann_whitney_ustatistic_results[article].append(list())\n",
    "        \n",
    "        \n",
    "        for num_before in range(10):\n",
    "\n",
    "            article_results[article][\"focus\"][\"alpha\"].append(list())\n",
    "            article_results[article][\"focus\"][\"theta\"].append(list())\n",
    "            article_results[article][\"focus\"][\"beta\"].append(list())\n",
    "\n",
    "            article_results[article][\"unfocus\"][\"alpha\"].append(list())\n",
    "            article_results[article][\"unfocus\"][\"theta\"].append(list())\n",
    "            article_results[article][\"unfocus\"][\"beta\"].append(list())\n",
    "\n",
    "            article_sem_results[article][\"focus\"][\"alpha\"].append(list())\n",
    "            article_sem_results[article][\"focus\"][\"theta\"].append(list())\n",
    "            article_sem_results[article][\"focus\"][\"beta\"].append(list())\n",
    "\n",
    "            article_sem_results[article][\"unfocus\"][\"alpha\"].append(list())\n",
    "            article_sem_results[article][\"unfocus\"][\"theta\"].append(list())\n",
    "            article_sem_results[article][\"unfocus\"][\"beta\"].append(list())\n",
    "            \n",
    "            # Initialize interval lists corresponding to interval bins\n",
    "            for i in range(len(intervals)) :\n",
    "                mann_whitney_pvalue_results[article][i].append(list())\n",
    "                mann_whitney_ustatistic_results[article][i].append(list())\n",
    "\n",
    "            print(num_before)\n",
    "\n",
    "            for num_after in range(10): \n",
    "                unfocused_state = list(((df_article[\"is_pressed\"] == False) & (df_article[\"is_target\"] == True)) | ((df_article[\"is_pressed\"] == True) & (df_article[\"is_target\"] == False)))\n",
    "\n",
    "                unfocused_state = getSmoothedPerformance(unfocused_state, num_before, num_after)\n",
    "                for i, state in enumerate(unfocused_state):\n",
    "                    unfocused_states[\"timepoint\"].append(i)\n",
    "                    unfocused_states[\"article_num_before_after\"].append((article, num_before, num_after))\n",
    "                    unfocused_states[\"unfocused_times\"].append(state)\n",
    "\n",
    "\n",
    "                #print(unfocused_state)\n",
    "                unfocused_df = df_article[unfocused_state]\n",
    "                focused_df = df_article[np.logical_not(unfocused_state)]\n",
    "\n",
    "                if(len(unfocused_df) == 0 or len(focused_df) == 0) :\n",
    "                    article_results[article][\"focus\"][\"alpha\"][num_before].append(0)\n",
    "                    article_results[article][\"focus\"][\"theta\"][num_before].append(0)\n",
    "                    article_results[article][\"focus\"][\"beta\"][num_before].append(0)\n",
    "\n",
    "                    article_results[article][\"unfocus\"][\"alpha\"][num_before].append(0)\n",
    "                    article_results[article][\"unfocus\"][\"theta\"][num_before].append(0)\n",
    "                    article_results[article][\"unfocus\"][\"beta\"][num_before].append(0)\n",
    "\n",
    "                    article_sem_results[article][\"focus\"][\"alpha\"][num_before].append(0)\n",
    "                    article_sem_results[article][\"focus\"][\"theta\"][num_before].append(0)\n",
    "                    article_sem_results[article][\"focus\"][\"beta\"][num_before].append(0)\n",
    "\n",
    "                    article_sem_results[article][\"unfocus\"][\"alpha\"][num_before].append(0)\n",
    "                    article_sem_results[article][\"unfocus\"][\"theta\"][num_before].append(0)\n",
    "                    article_sem_results[article][\"unfocus\"][\"beta\"][num_before].append(0)\n",
    "                    \n",
    "                    for i in range(len(intervals)) :\n",
    "                        mann_whitney_pvalue_results[article][i][num_before].append(0)\n",
    "                        mann_whitney_ustatistic_results[article][i][num_before].append(0)\n",
    "                else : \n",
    "                    f_df, u_df = getTimeBalanced(focused_df, unfocused_df, window_size=max(2, (num_before + num_after + 5)))\n",
    "\n",
    "#                     if(num_before == 3 and num_after == 8) :\n",
    "#                         plt.figure(figsize=(20,10))\n",
    "#                         plt.scatter(focused_df[\"data_index\"].values, [1]*len(focused_df[\"data_index\"].values))\n",
    "#                         plt.scatter(unfocused_df[\"data_index\"].values, [1]*len(unfocused_df[\"data_index\"].values))\n",
    "\n",
    "#                         plt.scatter(f_df[\"data_index\"].values, [0]*len(f_df[\"data_index\"].values))\n",
    "#                         plt.scatter(u_df[\"data_index\"].values, [0]*len(u_df[\"data_index\"].values))\n",
    "\n",
    "#                         plt.show()\n",
    "                    \n",
    "                    focused_eeg = tidyEEGList(getEEGFromDataFrame_AvgLeftRight(f_df, data_type=data_type))\n",
    "                    focused_power_ratios = np.array([getPowerRatio(data, binning) for data in focused_eeg])\n",
    "                    focused_power_ratio_avg = np.mean(focused_power_ratios, axis=0)\n",
    "                    SEM_focused_power_ratio = getSEM(focused_power_ratios)\n",
    "\n",
    "                \n",
    "                    unfocused_eeg = tidyEEGList(getEEGFromDataFrame_AvgLeftRight(u_df, data_type=data_type))\n",
    "                    unfocused_power_ratios = np.array([getPowerRatio(data, binning) for data in unfocused_eeg])\n",
    "                    unfocused_power_ratio_avg = np.mean(unfocused_power_ratios, axis=0)\n",
    "                    SEM_unfocused_power_ratio = getSEM(unfocused_power_ratios)\n",
    "                    \n",
    "                    for i in range(len(intervals)): \n",
    "                        mann_whitney = sp.stats.mannwhitneyu(focused_power_ratios[:,i], unfocused_power_ratios[:,i] )\n",
    "                        mann_whitney_pvalue_results[article][i][num_before].append(mann_whitney.pvalue)\n",
    "                        mann_whitney_ustatistic_results[article][i][num_before].append(mann_whitney.statistic)\n",
    "                    \n",
    "                    #focused_power_ratio_avg, SEM_focused_power_ratio = getPowerRatioAvgSEM(getEEGFromDataFrame_AvgLeftRight(f_df, data_type=data_type))\n",
    "                    #unfocused_power_ratio_avg, SEM_unfocused_power_ratio = getPowerRatioAvgSEM(getEEGFromDataFrame_AvgLeftRight(u_df, data_type=data_type))\n",
    "\n",
    "\n",
    "                    article_results[article][\"focus\"][\"alpha\"][num_before].append(focused_power_ratio_avg[2])\n",
    "                    article_results[article][\"focus\"][\"theta\"][num_before].append(focused_power_ratio_avg[0])\n",
    "                    article_results[article][\"focus\"][\"beta\"][num_before].append(focused_power_ratio_avg[1])\n",
    "\n",
    "                    article_results[article][\"unfocus\"][\"alpha\"][num_before].append(unfocused_power_ratio_avg[2])\n",
    "                    article_results[article][\"unfocus\"][\"theta\"][num_before].append(unfocused_power_ratio_avg[0])\n",
    "                    article_results[article][\"unfocus\"][\"beta\"][num_before].append(unfocused_power_ratio_avg[1])\n",
    "\n",
    "                    article_sem_results[article][\"focus\"][\"alpha\"][num_before].append(SEM_focused_power_ratio[2])\n",
    "                    article_sem_results[article][\"focus\"][\"theta\"][num_before].append(SEM_focused_power_ratio[0])\n",
    "                    article_sem_results[article][\"focus\"][\"beta\"][num_before].append(SEM_focused_power_ratio[1])\n",
    "\n",
    "                    article_sem_results[article][\"unfocus\"][\"alpha\"][num_before].append(SEM_unfocused_power_ratio[2])\n",
    "                    article_sem_results[article][\"unfocus\"][\"theta\"][num_before].append(SEM_unfocused_power_ratio[0])\n",
    "                    article_sem_results[article][\"unfocus\"][\"beta\"][num_before].append(SEM_unfocused_power_ratio[1])\n",
    "\n",
    "    # Visualize the different cases we're considering\n",
    "    unfocused_states_df = pd.DataFrame(unfocused_states)\n",
    "    \n",
    "                   \n",
    "else :\n",
    "    article_results = loadPickle(article_results_path)\n",
    "    article_sem_results = loadPickle(article_results_sem_path)\n",
    "    unfocused_states_df = loadPickle(unfocused_states_df_path)\n",
    "    mann_whitney_pvalue_results = loadPickle(pvalue_path)\n",
    "    mann_whitney_ustatistic_results = loadPickle(ustatistic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = unfocused_states_df.pivot(\"article_num_before_after\", \"timepoint\", \"unfocused_times\")\n",
    "pivoted = pivoted.fillna(False)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(\"Unfocused States (white)\")\n",
    "ax = sns.heatmap(pivoted, cbar=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann whitney heatmaps of differences to see what is best to use\n",
    "for j in range(0, len(intervals)):\n",
    "    bin_index = j\n",
    "    bin_mann_whitney_list = []\n",
    "    for i in range(1, numSections+1):\n",
    "        if i in mann_whitney_pvalue_results:\n",
    "            result = np.array(mann_whitney_pvalue_results[i][bin_index])\n",
    "            bin_mann_whitney_list.append(fdrcorrection(result)[1])\n",
    "\n",
    "    # Average them to see which would actually be best\n",
    "    result = np.mean(bin_mann_whitney_list, axis=0)\n",
    "    print(\"min pvalue:\",np.min(result), \"at\", np.where(result == np.min(result)))\n",
    "    ax = sns.heatmap(result)\n",
    "    plt.title(\"Pvalue on bin index \"+str(bin_index)+\" with different before and after estimation\")\n",
    "    plt.xlabel(\"num After\")\n",
    "    plt.ylabel(\"num Before\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mann whitney heatmaps of differences to see what is best to use\n",
    "for j in range(len(intervals)):\n",
    "    bin_index = j\n",
    "    bin_mann_whitney_list = []\n",
    "    for i in range(1, numSections+1):\n",
    "        if i in mann_whitney_ustatistic_results:\n",
    "            result = np.array(mann_whitney_ustatistic_results[i][bin_index])\n",
    "            bin_mann_whitney_list.append(result)\n",
    "\n",
    "    # Average them to see which would actually be best\n",
    "    result = np.mean(bin_mann_whitney_list, axis=0)\n",
    "    print(\"min U statistic:\",np.min(result), \"at\", np.where(result == np.min(result)))\n",
    "    ax = sns.heatmap(result, vmax=100)\n",
    "    plt.title(\"U Statistic on bin index \"+str(bin_index)+\" with different before and after estimation\")\n",
    "    plt.xlabel(\"num After\")\n",
    "    plt.ylabel(\"num Before\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha heatmaps of differences to see what is best to use\n",
    "average_alpha_diff_list = []\n",
    "average_alpha_SEM_accounted_diff_list = []\n",
    "for i in range(1, numSections+1):\n",
    "    if i in article_results.keys() and len(article_results[i][\"focus\"][\"alpha\"][0])>0:\n",
    "        result = np.array(article_results[i][\"focus\"][\"alpha\"]) - np.array(article_results[i][\"unfocus\"][\"alpha\"])\n",
    "        average_alpha_diff_list.append(result)\n",
    "        \n",
    "        result_sem = np.array(article_sem_results[i][\"focus\"][\"alpha\"]) + np.array(article_sem_results[i][\"unfocus\"][\"alpha\"])\n",
    "        average_alpha_SEM_accounted_diff_list.append(np.abs(result) - result_sem)\n",
    "        \n",
    "# Average them to see which would actually be best\n",
    "result = np.mean(average_alpha_diff_list, axis=0)\n",
    "ax = sns.heatmap(result)\n",
    "plt.title(\"Average alpha difference with different before and after estimation\")\n",
    "plt.xlabel(\"num After\")\n",
    "plt.ylabel(\"num Before\")\n",
    "plt.show()\n",
    "\n",
    "# Average them to see which would actually be best\n",
    "result = np.mean(average_alpha_SEM_accounted_diff_list, axis=0)\n",
    "print(\"max sem accounted diff:\",np.max(result), \"at\", np.where(result == np.max(result)))\n",
    "ax = sns.heatmap(result)\n",
    "plt.title(\"Average alpha difference with sem accounted before and after estimation\")\n",
    "plt.xlabel(\"num After\")\n",
    "plt.ylabel(\"num Before\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta heatmaps of differences to see what is best to use\n",
    "average_beta_diff_list = []\n",
    "average_beta_SEM_accounted_diff_list = []\n",
    "for i in range(1, numSections+1):\n",
    "    if i in article_results.keys() and len(article_results[i][\"focus\"][\"beta\"][0])>0:\n",
    "        result = np.array(article_results[i][\"focus\"][\"beta\"]) - np.array(article_results[i][\"unfocus\"][\"beta\"])\n",
    "        average_beta_diff_list.append(result)\n",
    "        \n",
    "        result_sem = np.array(article_sem_results[i][\"focus\"][\"beta\"]) + np.array(article_sem_results[i][\"unfocus\"][\"beta\"])\n",
    "        average_beta_SEM_accounted_diff_list.append(np.abs(result) - result_sem)\n",
    "\n",
    "# Average them to see which would actually be best\n",
    "result = np.mean(average_beta_diff_list, axis=0)\n",
    "ax = sns.heatmap(result)\n",
    "plt.title(\"Average beta difference with different before and after estimation\")\n",
    "plt.xlabel(\"num After\")\n",
    "plt.ylabel(\"num Before\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Average them to see which would actually be best\n",
    "result = np.mean(average_beta_SEM_accounted_diff_list, axis=0)\n",
    "print(\"max sem accounted diff:\",np.max(result), \"at\", np.where(result == np.max(result)))\n",
    "ax = sns.heatmap(result)\n",
    "plt.title(\"Average beta difference with sem accounted before and after estimation\")\n",
    "plt.xlabel(\"num After\")\n",
    "plt.ylabel(\"num Before\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theta heatmaps of differences to see what is best to use\n",
    "average_theta_diff_list = []\n",
    "average_theta_SEM_accounted_diff_list = []\n",
    "for i in range(1, numSections+1):\n",
    "    if i in article_results.keys() and len(article_results[i][\"focus\"][\"theta\"][0])>0:\n",
    "        result = np.array(article_results[i][\"focus\"][\"theta\"]) - np.array(article_results[i][\"unfocus\"][\"theta\"])\n",
    "        average_theta_diff_list.append(result)\n",
    "    \n",
    "        result_sem = np.array(article_sem_results[i][\"focus\"][\"theta\"]) + np.array(article_sem_results[i][\"unfocus\"][\"theta\"])\n",
    "        average_theta_SEM_accounted_diff_list.append(np.abs(result) - result_sem)\n",
    "\n",
    "# Average them to see which would actually be best\n",
    "result = np.mean(average_theta_diff_list, axis=0)\n",
    "ax = sns.heatmap(result)\n",
    "plt.title(\"Average theta difference with different before and after estimation\")\n",
    "plt.xlabel(\"num After\")\n",
    "plt.ylabel(\"num Before\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Average them to see which would actually be best\n",
    "result = np.mean(average_theta_SEM_accounted_diff_list, axis=0)\n",
    "print(\"max sem accounted diff:\",np.max(result), \"at\", np.where(result == np.max(result)))\n",
    "\n",
    "ax = sns.heatmap(result)\n",
    "plt.title(\"Average theta difference with sem accounted before and after estimation\")\n",
    "plt.xlabel(\"num After\")\n",
    "plt.ylabel(\"num Before\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_num_before = 7\n",
    "optimal_num_after = 6\n",
    "df_article=df\n",
    "unfocused_state = list(((df_article[\"is_pressed\"] == False) & (df_article[\"is_target\"] == True)) | ((df_article[\"is_pressed\"] == True) & (df_article[\"is_target\"] == False)))\n",
    "unfocused_state = getSmoothedPerformance(unfocused_state, optimal_num_before, optimal_num_after)\n",
    "unfocused_df = df_article[unfocused_state]\n",
    "focused_df = df_article[np.logical_not(unfocused_state)]\n",
    "\n",
    "f_df, u_df = getTimeBalanced(focused_df, unfocused_df, window_size=max(2, (optimal_num_before + optimal_num_after + 5)))\n",
    "\n",
    "f_power_ratios = list()\n",
    "for eeg_data in getEEGFromDataFrame_AvgLeftRight(f_df, data_type=data_type):\n",
    "    f_power_ratios.append(getPowerRatio(eeg_data, binning))\n",
    "u_power_ratios = list()\n",
    "for eeg_data in getEEGFromDataFrame_AvgLeftRight(u_df, data_type=data_type):\n",
    "    u_power_ratios.append(getPowerRatio(eeg_data, binning))\n",
    "    \n",
    "f_power_ratios = np.array(f_power_ratios)\n",
    "u_power_ratios = np.array(u_power_ratios)\n",
    "\n",
    "\n",
    "focus_theta_power_ratios = f_power_ratios[:, 0]\n",
    "unfocus_theta_power_ratios = u_power_ratios[:, 0]\n",
    "\n",
    "sp.stats.mannwhitneyu(focus_theta_power_ratios, unfocus_theta_power_ratios )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(focus_theta_power_ratios, [1] * len(focus_theta_power_ratios), label=\"focus\")\n",
    "plt.scatter(unfocus_theta_power_ratios, [0] * len(unfocus_theta_power_ratios), label=\"unfocus\")\n",
    "plt.xlabel(\"Theta Power\")\n",
    "plt.ylabel(\"focus or unfocus\")\n",
    "plt.title(\"Theta power distributions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.hist(focus_theta_power_ratios, bins=50, alpha=0.5, label=\"focus\")\n",
    "plt.hist(unfocus_theta_power_ratios, bins=50, alpha=0.5, label=\"unfocus\")\n",
    "plt.xlabel(\"Theta Power\")\n",
    "plt.ylabel(\"number of each state in each bin\")\n",
    "plt.title(\"Histogram distribution of focus and unfocus\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "X = np.append(f_power_ratios, u_power_ratios, axis=0)\n",
    "print(\"num training samples\", len(X))\n",
    "y = np.append(np.array([1] * len(f_power_ratios)), np.array([0] * len(u_power_ratios)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "lda = LDA()\n",
    "fit = lda.fit(X_train, y_train)\n",
    "y_predict = lda.predict(X_test)\n",
    "lda.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot power distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(np.array(f_power_ratios)[:, 0], np.array(f_power_ratios)[:, 1], np.array(f_power_ratios)[:, 2], label=\"focus\")\n",
    "ax.scatter(np.array(u_power_ratios)[:, 0], np.array(u_power_ratios)[:, 1], np.array(f_power_ratios)[:, 2], label=\"unfocus\")\n",
    "plt.legend()\n",
    "ax.set_xlabel(\"theta power\")\n",
    "ax.set_ylabel(\"alpha power\")\n",
    "ax.set_zlabel(\"beta power\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(f_power_ratios)[:, 0], np.array(f_power_ratios)[:, 1], label=\"focus\")\n",
    "plt.scatter(np.array(u_power_ratios)[:, 0], np.array(u_power_ratios)[:, 1], label=\"unfocus\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"theta power\")\n",
    "plt.ylabel(\"alpha power\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(f_power_ratios)[:, 0], np.array(f_power_ratios)[:, 2], label=\"focus\")\n",
    "plt.scatter(np.array(u_power_ratios)[:, 0], np.array(u_power_ratios)[:, 2], label=\"unfocus\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"theta power\")\n",
    "plt.ylabel(\"beta power\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = np.min([np.array(u_power_ratios)[:, 0], np.array(f_power_ratios)[:, 0]])\n",
    "x_max = np.max([np.array(u_power_ratios)[:, 0], np.array(f_power_ratios)[:, 0]])\n",
    "\n",
    "y_min = np.min([np.array(u_power_ratios)[:, 2], np.array(f_power_ratios)[:, 2]])\n",
    "y_max = np.max([np.array(u_power_ratios)[:, 2], np.array(f_power_ratios)[:, 2]])\n",
    "\n",
    "x_bins = np.linspace(x_min,x_max,10)\n",
    "y_bins = np.linspace(y_min,y_max,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_unfocus, a, b, c = plt.hist2d(np.array(u_power_ratios)[:, 0], np.array(u_power_ratios)[:, 2], bins=[x_bins,y_bins]);\n",
    "\n",
    "plt.xlabel(\"theta values\")\n",
    "plt.ylabel(\"beta values\")\n",
    "plt.title(\"histogram binning of unfocus counts with theta vs beta values as such\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_focus, af, bf, _ = plt.hist2d(np.array(f_power_ratios)[:, 0], np.array(f_power_ratios)[:, 2], bins=[x_bins,y_bins]);\n",
    "plt.xlabel(\"theta values\")\n",
    "plt.ylabel(\"beta values\")\n",
    "plt.title(\"histogram binning of focus counts with theta vs beta values as such\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = count_focus - count_unfocus \n",
    "\n",
    "print(\"max theta beta diff:\",np.max(diff), \"at\", np.where(diff == np.max(diff)))\n",
    "print(\"min theta beta diff:\",np.min(diff), \"at\", np.where(diff == np.min(diff)))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "ax = sns.heatmap(np.flipud(np.transpose(diff)), xticklabels=a, yticklabels=np.flip(b))\n",
    "plt.title(\"quantity differences in theta vs beta quantities\")\n",
    "plt.xlabel(\"theta values\")\n",
    "plt.ylabel(\"beta values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look at the optimal focus model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.scatter(focused_df[\"data_index\"].values, [1]*len(focused_df[\"data_index\"].values))\n",
    "plt.scatter(unfocused_df[\"data_index\"].values, [1]*len(unfocused_df[\"data_index\"].values))\n",
    "\n",
    "plt.scatter(f_df[\"data_index\"].values, [0]*len(f_df[\"data_index\"].values))\n",
    "plt.scatter(u_df[\"data_index\"].values, [0]*len(u_df[\"data_index\"].values))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "focused_df=f_df.copy()\n",
    "unfocused_df=u_df.copy()\n",
    "\n",
    "\n",
    "focused_power_ratio_avg, SEM_focused_power_ratio = getPowerRatioAvgSEM(getEEGFromDataFrame_AvgLeftRight(focused_df, data_type=data_type))\n",
    "unfocused_power_ratio_avg, SEM_unfocused_power_ratio = getPowerRatioAvgSEM(getEEGFromDataFrame_AvgLeftRight(unfocused_df, data_type=data_type))\n",
    "\n",
    "\n",
    "focused_freqs, focused_psds, focused_psd_avg = getFreqsAndPSD(tidyEEGList(getEEGFromDataFrame_AvgLeftRight(focused_df, data_type=data_type))) \n",
    "focused_psd_sem = getSEM(np.log(focused_psds))\n",
    "\n",
    "unfocused_freqs, unfocused_psds, unfocused_psd_avg = getFreqsAndPSD(tidyEEGList(getEEGFromDataFrame_AvgLeftRight(unfocused_df, data_type=data_type)))\n",
    "unfocused_psd_sem = getSEM(np.log(unfocused_psds))\n",
    "\n",
    "\n",
    "plot_window_size = 30\n",
    "\n",
    "\n",
    "freq1 = focused_freqs[:plot_window_size]\n",
    "psd1 = np.log(focused_psd_avg[:plot_window_size])\n",
    "sem1 = focused_psd_sem[:plot_window_size]\n",
    "\n",
    "plt.plot(freq1, psd1, label=\"focus\")\n",
    "plt.fill_between(freq1, psd1-sem1, psd1+sem1, alpha = 0.2)\n",
    "\n",
    "freq2 = unfocused_freqs[:plot_window_size]\n",
    "psd2 = np.log(unfocused_psd_avg[:plot_window_size])\n",
    "sem2 = unfocused_psd_sem[:plot_window_size]\n",
    "\n",
    "plt.plot(freq2, psd2, label=\"unfocus\")\n",
    "plt.fill_between(freq2, psd2-sem2, psd2+sem2, alpha = 0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Power spectrum all articles together\")\n",
    "plt.xlabel(\"Hz\")\n",
    "plt.ylabel(\"Power log(Hz)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"num focus\", len(focused_df), \"num unfocus\", len(unfocused_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Closer look at the optimal focus model\n",
    "\n",
    "focus_eeg_list = list()\n",
    "unfocus_eeg_list = list()\n",
    "\n",
    "for i in range(1, numSections + 1): \n",
    "    df_article=df[df[\"section_number\"] == i]\n",
    "    unfocused_state = getSmoothedPerformance(list((df_article[\"is_pressed\"] == False) & (df_article[\"is_target\"] == True)), optimal_num_before, optimal_num_after)\n",
    "    unfocused_df = df_article[unfocused_state]\n",
    "    focused_df = df_article[np.logical_not(unfocused_state)]\n",
    "    \n",
    "    if (len(focused_df)==0 or len(unfocused_df)==0):\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    focused_df, unfocused_df = getTimeBalanced(focused_df, unfocused_df, window_size=max(2, (optimal_num_before + optimal_num_after + 5)))\n",
    "\n",
    "    focus_eeg_list.extend(getEEGFromDataFrame_AvgLeftRight(focused_df, data_type=data_type))\n",
    "    unfocus_eeg_list.extend(getEEGFromDataFrame_AvgLeftRight(unfocused_df, data_type=data_type))\n",
    "    \n",
    "    plt.plot(unfocused_state)\n",
    "    plt.title(\"Article:\" + str(i))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    focused_freqs, focused_psds, focused_psd_avg = getFreqsAndPSD(tidyEEGList(getEEGFromDataFrame_AvgLeftRight(focused_df, data_type=data_type))) \n",
    "    focused_psd_sem = getSEM(np.log(focused_psds))\n",
    "\n",
    "    unfocused_freqs, unfocused_psds, unfocused_psd_avg = getFreqsAndPSD(tidyEEGList(getEEGFromDataFrame_AvgLeftRight(unfocused_df, data_type=data_type)))\n",
    "    unfocused_psd_sem = getSEM(np.log(unfocused_psds))\n",
    "\n",
    "\n",
    "    plot_window_size = 30\n",
    "\n",
    "\n",
    "    freq1 = focused_freqs[:plot_window_size]\n",
    "    psd1 = np.log(focused_psd_avg[:plot_window_size])\n",
    "    sem1 = focused_psd_sem[:plot_window_size]\n",
    "\n",
    "    plt.plot(freq1, psd1, label=\"focus\")\n",
    "    plt.fill_between(freq1, psd1-sem1, psd1+sem1, alpha = 0.2)\n",
    "\n",
    "    freq2 = unfocused_freqs[:plot_window_size]\n",
    "    psd2 = np.log(unfocused_psd_avg[:plot_window_size])\n",
    "    sem2 = unfocused_psd_sem[:plot_window_size]\n",
    "\n",
    "    plt.plot(freq2, psd2, label=\"unfocus\")\n",
    "    plt.fill_between(freq2, psd2-sem2, psd2+sem2, alpha = 0.2)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Power spectrum of one article\")\n",
    "    plt.xlabel(\"Hz\")\n",
    "    plt.ylabel(\"Power log(Hz)\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"num focus\", len(focused_df), \"num unfocus\", len(unfocused_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_power_ratio_avg, SEM_focused_power_ratio = getPowerRatioAvgSEM(focus_eeg_list)\n",
    "unfocused_power_ratio_avg, SEM_unfocused_power_ratio = getPowerRatioAvgSEM(unfocus_eeg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Power Bin comparisons across all articles\")\n",
    "\n",
    "plotMultipleBarGraphs([focused_power_ratio_avg, unfocused_power_ratio_avg], 0.15, [\"focused\",\"unfocused\"], intervals, error_values=[SEM_focused_power_ratio, SEM_unfocused_power_ratio])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write article data to files\n",
    "ensureDirExists(article_results_directory)\n",
    "writeToPickle(article_results, article_results_path)\n",
    "\n",
    "\n",
    "ensureDirExists(article_results_sem_directory)\n",
    "writeToPickle(article_sem_results, article_results_sem_path)\n",
    "\n",
    "ensureDirExists(states_df_directory)\n",
    "writeToPickle(states_df, states_df_path)\n",
    "\n",
    "ensureDirExists(ustatistic_directory)\n",
    "writeToPickle(mann_whitney_ustatistic_results, ustatistic_path)\n",
    "\n",
    "ensureDirExists(pvalue_directory)\n",
    "writeToPickle(mann_whitney_pvalue_results, pvalue_path)\n",
    "\n",
    "\n",
    "print(\"Done!\")\n",
    "print(foldername, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
