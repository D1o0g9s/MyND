{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Braindecode CNN training and prediction \n",
    "This notebook loads epoched dataframes and trains a braindecode models on the two possible classes. Both trialwise and cropped are implemented. Saving the models is easy and can be imported to a different notebook for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from helperFunctions import *\n",
    "from constants import *\n",
    "from dataAnalysisFunctions import getSEM, getCleanedSignal, getIntervals, getPowerRatio\n",
    "import pandas as pd\n",
    "\n",
    "from featureBuilder import featureBuilder\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataframes and variables needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from memory\n",
    "foldername='P001'\n",
    "filename='part_P001_block_S004'\n",
    "#filtered_data = loadData(datatype='filtered_data', foldername=foldername, filename=filename)\n",
    "#filtered_cleaned_data = loadData(datatype='filtered_cleaned_data', foldername=foldername, filename=filename)\n",
    "df = loadData(datatype='dataframe_filtered', foldername=foldername, filename=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from memory\n",
    "foldername='P001'\n",
    "filename='part_P001_block_S005'\n",
    "#filtered_data = loadData(datatype='filtered_data', foldername=foldername, filename=filename)\n",
    "#filtered_cleaned_data = loadData(datatype='filtered_cleaned_data', foldername=foldername, filename=filename)\n",
    "df2 = loadData(datatype='dataframe_filtered', foldername=foldername, filename=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStateDF(df):\n",
    "    # Select the trials needed to classify\n",
    "    focused_state = df[\"trial_time\"] == 0.7\n",
    "    unfocused_state = df[\"trial_time\"] > 0.9\n",
    "    med_state = ((df[\"trial_time\"] > 0.7) & (df[\"trial_time\"] <= 0.9))\n",
    "\n",
    "    focused_df = df[focused_state]\n",
    "    unfocused_df = df[unfocused_state]\n",
    "    med_df = df[med_state]\n",
    "    \n",
    "    return focused_df, unfocused_df, med_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_df, unfocused_df, med_df = getStateDF(df)\n",
    "focused_df2, unfocused_df2, med_df2 = getStateDF(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_df = focused_df.append(focused_df2)\n",
    "unfocused_df = unfocused_df.append(unfocused_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "focused: 423 unfocused: 601\n"
     ]
    }
   ],
   "source": [
    "# Create lists of just the epochs and corresponding focus level\n",
    "data_type = \"data_extended\"\n",
    "focused_epochs = []\n",
    "focused_y = []\n",
    "\n",
    "for idx, row in focused_df.iterrows(): \n",
    "    focused_epochs.append(np.array(row[data_type][StreamType.EEG.value][StreamType.DATA.value]))\n",
    "    focused_y.append(1)\n",
    "\n",
    "unfocused_epochs = []\n",
    "unfocused_y = []\n",
    "for idx, row in unfocused_df.iterrows(): \n",
    "    unfocused_epochs.append(np.array(row[data_type][StreamType.EEG.value][StreamType.DATA.value]))\n",
    "    unfocused_y.append(0)\n",
    "    \n",
    "print(\"focused:\", len(focused_y), \"unfocused:\", len(unfocused_y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipShuffle(A, B):\n",
    "    C = list(zip(A, B))\n",
    "    random.shuffle(C)\n",
    "    A, B = zip(*C)\n",
    "    return np.array(A), np.array(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the two sets the same length\n",
    "focused_epochs = tidyEEGList(np.array(focused_epochs))\n",
    "unfocused_epochs = tidyEEGList(np.array(unfocused_epochs))\n",
    "\n",
    "focused_epochs, focused_y = zipShuffle(focused_epochs, focused_y)\n",
    "unfocused_epochs, unfocused_y = zipShuffle(unfocused_epochs, unfocused_y)\n",
    "\n",
    "num_per_type = min(len(focused_y), len(unfocused_y))\n",
    "\n",
    "focused_epochs, focused_y = focused_epochs[:num_per_type], focused_y[:num_per_type]\n",
    "unfocused_epochs, unfocused_y = unfocused_epochs[:num_per_type], unfocused_y[:num_per_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "846"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X and y matrices \n",
    "X = np.array(list(focused_epochs) + list(unfocused_epochs))\n",
    "y = np.array(list(focused_y) + list(unfocused_y))\n",
    "\n",
    "X = tidyEEGList(X)\n",
    "X = np.array([np.transpose(X[i]) for i in range(len(X))])\n",
    "\n",
    "X, y = zipShuffle(X, y)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data up\n",
    "percent_train = 0.7\n",
    "num_train = int(len(X) * percent_train)\n",
    "percent_valid = 0.2\n",
    "num_valid = int(len(X) * percent_valid)\n",
    "\n",
    "train_set = SignalAndTarget(X[:num_train], y[:num_train])\n",
    "valid_set = SignalAndTarget(X[num_train:num_train + num_valid], y[num_train:num_train + num_valid])\n",
    "test_set = SignalAndTarget(X[num_train + num_valid:], y=y[num_train + num_valid:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(776, 8, 546)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trialwise Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_misclass</th>\n",
       "      <th>valid_misclass</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.382881</td>\n",
       "      <td>1.455629</td>\n",
       "      <td>0.462838</td>\n",
       "      <td>0.473373</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.655319</td>\n",
       "      <td>0.691541</td>\n",
       "      <td>0.364865</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>5.445997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.682284</td>\n",
       "      <td>0.848024</td>\n",
       "      <td>0.383446</td>\n",
       "      <td>0.437870</td>\n",
       "      <td>5.464340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.604569</td>\n",
       "      <td>0.733885</td>\n",
       "      <td>0.295608</td>\n",
       "      <td>0.414201</td>\n",
       "      <td>5.439598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.632555</td>\n",
       "      <td>0.874861</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>5.492461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.534902</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>0.278716</td>\n",
       "      <td>0.355030</td>\n",
       "      <td>5.424477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.564443</td>\n",
       "      <td>0.808533</td>\n",
       "      <td>0.290541</td>\n",
       "      <td>0.420118</td>\n",
       "      <td>5.366806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.518813</td>\n",
       "      <td>0.743238</td>\n",
       "      <td>0.258446</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>5.678066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.520349</td>\n",
       "      <td>0.806382</td>\n",
       "      <td>0.246622</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>5.637397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.480389</td>\n",
       "      <td>0.659013</td>\n",
       "      <td>0.244932</td>\n",
       "      <td>0.360947</td>\n",
       "      <td>5.329871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.472823</td>\n",
       "      <td>0.667815</td>\n",
       "      <td>0.231419</td>\n",
       "      <td>0.360947</td>\n",
       "      <td>5.336207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.473232</td>\n",
       "      <td>0.664930</td>\n",
       "      <td>0.239865</td>\n",
       "      <td>0.372781</td>\n",
       "      <td>5.340988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.451597</td>\n",
       "      <td>0.692747</td>\n",
       "      <td>0.224662</td>\n",
       "      <td>0.355030</td>\n",
       "      <td>5.485249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.455332</td>\n",
       "      <td>0.722650</td>\n",
       "      <td>0.209459</td>\n",
       "      <td>0.366864</td>\n",
       "      <td>5.389171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.432389</td>\n",
       "      <td>0.659340</td>\n",
       "      <td>0.195946</td>\n",
       "      <td>0.343195</td>\n",
       "      <td>5.349907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.424836</td>\n",
       "      <td>0.670918</td>\n",
       "      <td>0.192568</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>5.510823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.424291</td>\n",
       "      <td>0.680962</td>\n",
       "      <td>0.190878</td>\n",
       "      <td>0.355030</td>\n",
       "      <td>5.486593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.422483</td>\n",
       "      <td>0.682559</td>\n",
       "      <td>0.185811</td>\n",
       "      <td>0.360947</td>\n",
       "      <td>5.527475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.412510</td>\n",
       "      <td>0.667797</td>\n",
       "      <td>0.184122</td>\n",
       "      <td>0.360947</td>\n",
       "      <td>5.449120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.412701</td>\n",
       "      <td>0.680641</td>\n",
       "      <td>0.192568</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>5.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.407309</td>\n",
       "      <td>0.665666</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.366864</td>\n",
       "      <td>5.575319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.403304</td>\n",
       "      <td>0.648817</td>\n",
       "      <td>0.185811</td>\n",
       "      <td>0.349112</td>\n",
       "      <td>5.536237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.400665</td>\n",
       "      <td>0.649830</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.349112</td>\n",
       "      <td>5.408736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.401042</td>\n",
       "      <td>0.649097</td>\n",
       "      <td>0.179054</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>5.333130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.399301</td>\n",
       "      <td>0.656106</td>\n",
       "      <td>0.179054</td>\n",
       "      <td>0.337278</td>\n",
       "      <td>5.349407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.397187</td>\n",
       "      <td>0.655895</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>5.369278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.395706</td>\n",
       "      <td>0.650944</td>\n",
       "      <td>0.173986</td>\n",
       "      <td>0.343195</td>\n",
       "      <td>5.379784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.395245</td>\n",
       "      <td>0.650139</td>\n",
       "      <td>0.173986</td>\n",
       "      <td>0.349112</td>\n",
       "      <td>5.346031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.395246</td>\n",
       "      <td>0.652216</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.337278</td>\n",
       "      <td>5.805429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.395172</td>\n",
       "      <td>0.653293</td>\n",
       "      <td>0.173986</td>\n",
       "      <td>0.343195</td>\n",
       "      <td>5.657778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.395342</td>\n",
       "      <td>0.652574</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.337278</td>\n",
       "      <td>5.985015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_loss  train_misclass  valid_misclass   runtime\n",
       "0     1.382881    1.455629        0.462838        0.473373  0.000000\n",
       "1     0.655319    0.691541        0.364865        0.402367  5.445997\n",
       "2     0.682284    0.848024        0.383446        0.437870  5.464340\n",
       "3     0.604569    0.733885        0.295608        0.414201  5.439598\n",
       "4     0.632555    0.874861        0.337838        0.455621  5.492461\n",
       "5     0.534902    0.657645        0.278716        0.355030  5.424477\n",
       "6     0.564443    0.808533        0.290541        0.420118  5.366806\n",
       "7     0.518813    0.743238        0.258446        0.402367  5.678066\n",
       "8     0.520349    0.806382        0.246622        0.402367  5.637397\n",
       "9     0.480389    0.659013        0.244932        0.360947  5.329871\n",
       "10    0.472823    0.667815        0.231419        0.360947  5.336207\n",
       "11    0.473232    0.664930        0.239865        0.372781  5.340988\n",
       "12    0.451597    0.692747        0.224662        0.355030  5.485249\n",
       "13    0.455332    0.722650        0.209459        0.366864  5.389171\n",
       "14    0.432389    0.659340        0.195946        0.343195  5.349907\n",
       "15    0.424836    0.670918        0.192568        0.331361  5.510823\n",
       "16    0.424291    0.680962        0.190878        0.355030  5.486593\n",
       "17    0.422483    0.682559        0.185811        0.360947  5.527475\n",
       "18    0.412510    0.667797        0.184122        0.360947  5.449120\n",
       "19    0.412701    0.680641        0.192568        0.378698  5.424100\n",
       "20    0.407309    0.665666        0.187500        0.366864  5.575319\n",
       "21    0.403304    0.648817        0.185811        0.349112  5.536237\n",
       "22    0.400665    0.649830        0.175676        0.349112  5.408736\n",
       "23    0.401042    0.649097        0.179054        0.331361  5.333130\n",
       "24    0.399301    0.656106        0.179054        0.337278  5.349407\n",
       "25    0.397187    0.655895        0.175676        0.331361  5.369278\n",
       "26    0.395706    0.650944        0.173986        0.343195  5.379784\n",
       "27    0.395245    0.650139        0.173986        0.349112  5.346031\n",
       "28    0.395246    0.652216        0.175676        0.337278  5.805429\n",
       "29    0.395172    0.653293        0.173986        0.343195  5.657778\n",
       "30    0.395342    0.652574        0.175676        0.337278  5.985015"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model_t = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=train_set.X.shape[2], \n",
    "                        #filter_time_length=4,\n",
    "                        final_conv_length='auto')\n",
    "if cuda:\n",
    "    model_t.cuda()\n",
    "    \n",
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model_t.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model_t.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)\n",
    "\n",
    "model_t.fit(train_set.X, train_set.y, epochs=30, batch_size=64, scheduler='cosine',\n",
    "         validation_data=(valid_set.X, valid_set.y),)\n",
    "\n",
    "model_t.epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4951760470867157,\n",
       " 'misclass': 0.23840206185567014,\n",
       " 'runtime': 0.0008199214935302734}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = SignalAndTarget(X[70:], y=y[70:])\n",
    "\n",
    "model_t.evaluate(test_set.X, test_set.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8243243243243243"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train_y = model_t.predict_classes(train_set.X)\n",
    "\n",
    "sum(train_set.y == pred_train_y) / len(pred_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627218934911243"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid_y = model_t.predict_classes(valid_set.X)\n",
    "\n",
    "sum(valid_set.y == pred_valid_y) / len(pred_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615979381443299"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_y = model_t.predict_classes(test_set.X)\n",
    "\n",
    "sum(test_set.y == pred_test_y) / len(pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.save(model_t, \"model_t_combined_filtered.pickle\")\n",
    "# torch.save(model_c, \"model_c_combined_filtered.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropped Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model_c = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=None, \n",
    "                        final_conv_length=12)\n",
    "if cuda:\n",
    "    model_c.cuda()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model_c.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model_c.compile(loss=F.nll_loss, optimizer=optimizer,  iterator_seed=1, cropped=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_misclass</th>\n",
       "      <th>valid_misclass</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764594</td>\n",
       "      <td>1.809530</td>\n",
       "      <td>0.501689</td>\n",
       "      <td>0.497041</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.694437</td>\n",
       "      <td>0.766192</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.437870</td>\n",
       "      <td>10.356950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.677484</td>\n",
       "      <td>0.784519</td>\n",
       "      <td>0.361486</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>10.888689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.643068</td>\n",
       "      <td>0.734710</td>\n",
       "      <td>0.332770</td>\n",
       "      <td>0.437870</td>\n",
       "      <td>11.013071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.633955</td>\n",
       "      <td>0.737799</td>\n",
       "      <td>0.319257</td>\n",
       "      <td>0.426036</td>\n",
       "      <td>10.933045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.607242</td>\n",
       "      <td>0.720494</td>\n",
       "      <td>0.300676</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>10.157255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.608859</td>\n",
       "      <td>0.722492</td>\n",
       "      <td>0.305743</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>10.048883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.598556</td>\n",
       "      <td>0.695825</td>\n",
       "      <td>0.302365</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>10.269390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.591692</td>\n",
       "      <td>0.717708</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.414201</td>\n",
       "      <td>10.483545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.583772</td>\n",
       "      <td>0.681220</td>\n",
       "      <td>0.282095</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>10.065620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.580794</td>\n",
       "      <td>0.694209</td>\n",
       "      <td>0.278716</td>\n",
       "      <td>0.396450</td>\n",
       "      <td>10.086311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.578864</td>\n",
       "      <td>0.700513</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.414201</td>\n",
       "      <td>10.603141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.577507</td>\n",
       "      <td>0.699286</td>\n",
       "      <td>0.273649</td>\n",
       "      <td>0.414201</td>\n",
       "      <td>9.993251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.568193</td>\n",
       "      <td>0.675440</td>\n",
       "      <td>0.266892</td>\n",
       "      <td>0.396450</td>\n",
       "      <td>9.977312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.567019</td>\n",
       "      <td>0.670146</td>\n",
       "      <td>0.265203</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>9.878083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.564909</td>\n",
       "      <td>0.667688</td>\n",
       "      <td>0.265203</td>\n",
       "      <td>0.390533</td>\n",
       "      <td>10.207264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.562141</td>\n",
       "      <td>0.676155</td>\n",
       "      <td>0.266892</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>11.069358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.561918</td>\n",
       "      <td>0.681464</td>\n",
       "      <td>0.268581</td>\n",
       "      <td>0.408284</td>\n",
       "      <td>11.848623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.557909</td>\n",
       "      <td>0.670466</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.402367</td>\n",
       "      <td>12.331891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.559838</td>\n",
       "      <td>0.681436</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.408284</td>\n",
       "      <td>13.480842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.555654</td>\n",
       "      <td>0.671438</td>\n",
       "      <td>0.260135</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>11.722250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.555101</td>\n",
       "      <td>0.666038</td>\n",
       "      <td>0.253378</td>\n",
       "      <td>0.372781</td>\n",
       "      <td>10.693943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.554318</td>\n",
       "      <td>0.668472</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>10.111455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.555105</td>\n",
       "      <td>0.674084</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>10.189407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.553452</td>\n",
       "      <td>0.670167</td>\n",
       "      <td>0.251689</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>9.970650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.553014</td>\n",
       "      <td>0.668801</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.372781</td>\n",
       "      <td>9.940646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.553224</td>\n",
       "      <td>0.670556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.372781</td>\n",
       "      <td>9.933288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.552769</td>\n",
       "      <td>0.670656</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.372781</td>\n",
       "      <td>10.107382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.552904</td>\n",
       "      <td>0.671664</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>10.001385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.552970</td>\n",
       "      <td>0.671723</td>\n",
       "      <td>0.256757</td>\n",
       "      <td>0.378698</td>\n",
       "      <td>10.251513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.552822</td>\n",
       "      <td>0.671283</td>\n",
       "      <td>0.255068</td>\n",
       "      <td>0.372781</td>\n",
       "      <td>10.169136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_loss  train_misclass  valid_misclass    runtime\n",
       "0     1.764594    1.809530        0.501689        0.497041   0.000000\n",
       "1     0.694437    0.766192        0.375000        0.437870  10.356950\n",
       "2     0.677484    0.784519        0.361486        0.461538  10.888689\n",
       "3     0.643068    0.734710        0.332770        0.437870  11.013071\n",
       "4     0.633955    0.737799        0.319257        0.426036  10.933045\n",
       "5     0.607242    0.720494        0.300676        0.402367  10.157255\n",
       "6     0.608859    0.722492        0.305743        0.384615  10.048883\n",
       "7     0.598556    0.695825        0.302365        0.378698  10.269390\n",
       "8     0.591692    0.717708        0.297297        0.414201  10.483545\n",
       "9     0.583772    0.681220        0.282095        0.378698  10.065620\n",
       "10    0.580794    0.694209        0.278716        0.396450  10.086311\n",
       "11    0.578864    0.700513        0.283784        0.414201  10.603141\n",
       "12    0.577507    0.699286        0.273649        0.414201   9.993251\n",
       "13    0.568193    0.675440        0.266892        0.396450   9.977312\n",
       "14    0.567019    0.670146        0.265203        0.384615   9.878083\n",
       "15    0.564909    0.667688        0.265203        0.390533  10.207264\n",
       "16    0.562141    0.676155        0.266892        0.402367  11.069358\n",
       "17    0.561918    0.681464        0.268581        0.408284  11.848623\n",
       "18    0.557909    0.670466        0.263514        0.402367  12.331891\n",
       "19    0.559838    0.681436        0.263514        0.408284  13.480842\n",
       "20    0.555654    0.671438        0.260135        0.384615  11.722250\n",
       "21    0.555101    0.666038        0.253378        0.372781  10.693943\n",
       "22    0.554318    0.668472        0.256757        0.384615  10.111455\n",
       "23    0.555105    0.674084        0.256757        0.378698  10.189407\n",
       "24    0.553452    0.670167        0.251689        0.378698   9.970650\n",
       "25    0.553014    0.668801        0.250000        0.372781   9.940646\n",
       "26    0.553224    0.670556        0.250000        0.372781   9.933288\n",
       "27    0.552769    0.670656        0.256757        0.372781  10.107382\n",
       "28    0.552904    0.671664        0.256757        0.378698  10.001385\n",
       "29    0.552970    0.671723        0.256757        0.378698  10.251513\n",
       "30    0.552822    0.671283        0.255068        0.372781  10.169136"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_time_length = train_set.X.shape[2]\n",
    "model_c.fit(train_set.X, train_set.y, epochs=30, batch_size=64, scheduler='cosine',\n",
    "          input_time_length=input_time_length,\n",
    "         validation_data=(valid_set.X, valid_set.y),)\n",
    "\n",
    "model_c.epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5938166975975037,\n",
       " 'misclass': 0.2860824742268041,\n",
       " 'runtime': 0.0004119873046875}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = SignalAndTarget(X[70:], y=y[70:])\n",
    "\n",
    "model_c.evaluate(test_set.X, test_set.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7449324324324325"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train_y = model_c.predict_classes(train_set.X)\n",
    "\n",
    "sum(train_set.y == pred_train_y) / len(pred_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6272189349112426"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid_y = model_c.predict_classes(valid_set.X)\n",
    "\n",
    "sum(valid_set.y == pred_valid_y) / len(pred_valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7139175257731959"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test_y = model_c.predict_classes(test_set.X)\n",
    "\n",
    "sum(test_set.y == pred_test_y) / len(pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1 = features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1_numpy = conv_layer_1.weight.data.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1_numpy = conv_layer_1_numpy.reshape(40, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "ax = sns.heatmap(conv_layer_1_numpy)\n",
    "plt.xlabel(\"Kernel\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.title(\"Weights of first layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2 = features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2_numpy = conv_layer_2.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_2_numpy = conv_layer_2_numpy.reshape(40, 40, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8): \n",
    "    ax = sns.heatmap(conv_layer_2_numpy[:,:,i])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.corrcoef(conv_layer_2_numpy[:,:,0], conv_layer_2_numpy[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doesn't work "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for p in model.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torchvision import utils\n",
    "\n",
    "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1): \n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params = []\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    #print(i)\n",
    "    #print(p)\n",
    "    #params.append(p)\n",
    "    visTensor(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def plot_weights(features, layer_num, single_channel = True, collated = False):\n",
    "  \n",
    "    #extracting the model features at the particular layer number\n",
    "    layer = features[layer_num]\n",
    "  \n",
    "    #checking whether the layer is convolution layer or not \n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        #getting the weight tensor data\n",
    "        weight_tensor = features[layer_num].weight.data\n",
    "        return weight_tensor\n",
    "        \n",
    "        #grid = vutils.make_grid(weight_tensor)\n",
    "        #show(grid)\n",
    "        #         if single_channel:\n",
    "        #             if collated:\n",
    "        #                 plot_filters_single_channel_big(weight_tensor)\n",
    "        #             else:\n",
    "        #                 plot_filters_single_channel(weight_tensor)\n",
    "\n",
    "        #         else:\n",
    "        #             if weight_tensor.shape[1] == 3:\n",
    "        #                 plot_filters_multi_channel(weight_tensor)\n",
    "        #             else:\n",
    "        #                 print(\"Can only plot weights with three channels with single channel = False\")\n",
    "\n",
    "    else:\n",
    "        print(\"Can only visualize layers which are convolutional\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import torchvision.utils as vutils\n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
