{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyND Offline Processing\n",
    "Author: Geeling Chau<br> \n",
    "Description: Process xdf files recorded from experimental sessions to determine file eligibility and data feature extraction.<br>\n",
    "Sources: \n",
    "- Ollie's Segment Speller Offline Processing Code https://github.com/ollie-d/SegSpeller/blob/master/Offline%20Processing.ipynb \n",
    "- neurodsp https://github.com/neurodsp-tools/neurodsp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helperFunctions import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default figure size larger! \n",
    "figure = {'figsize': (13,8)}\n",
    "plt.rc('figure', **figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Files that work with this notebook: \n",
    "exp001_session_EyeTrackerIncluded.xdf\n",
    "exp002_session_EyeTrackerIncluded.xdf # \"spacePressed\" appears after the text \n",
    "exp001_full.xdf # supposed good calibration but articles short incomplete run after 2nd article. (Connectionism?)\n",
    "exp002_full.xdf # iffy calibration but full run successful\n",
    "exp003_full_Crash after 2.xdf # Crashed after 2nd article (Wikipedia_DSP_1?)\n",
    "exp004_full.xdf # crash after instructions (Connectionism)\n",
    "participant_P004_exp001_block_Full.xdf # Crash at DSP_1, did not look at any of the memes\n",
    "'''\n",
    "\n",
    "XDF_Data = loadxdf(\"../data/participant_P004_exp001_block_Full.xdf\")\n",
    "if StreamType.EEG.value in XDF_Data : \n",
    "    eeg_fs = int(XDF_Data[StreamType.EEG.value][StreamType.FS.value])\n",
    "    print(\"eeg_fs = \", eeg_fs)\n",
    "if StreamType.EYE.value in XDF_Data : \n",
    "    time_differences_eye_tracker = [XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][i+1]-XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][i] for i in range(len(XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE])-1)]\n",
    "    mean_fs_eye_tracker = 1/np.mean(time_differences_eye_tracker)\n",
    "    eye_fs = int(mean_fs_eye_tracker)\n",
    "    print(\"eye_fs = \", eye_fs)\n",
    "# Trim the data to only include the time PsychoPy was running\n",
    "XDF_Data = epochByMarkIndex(0, -1, XDF_Data)\n",
    "\n",
    "markers = np.array(XDF_Data[MARKER_STREAM_TYPE][DATA_STREAM_TYPE][:,0])\n",
    "marker_indexes = {}\n",
    "for index, marker in enumerate(markers): \n",
    "    marker_indexes[marker] = index\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording data checks (whether all markers are there etc)\n",
    "markersFound = True\n",
    "for marker_key in PSYCHO_PY_MARKERS : \n",
    "    if PSYCHO_PY_MARKERS[marker_key] not in markers: \n",
    "        markersFound = False \n",
    "        print(\"Missing Marker:\", PSYCHO_PY_MARKERS[marker_key])\n",
    "print(\"All Markers Found?\", markersFound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = {}\n",
    "end_times = {}\n",
    "#start_times[StreamType.EEG.value] = XDF_Data[StreamType.EEG.value][StreamType.TIME.value][0]\n",
    "#end_times[EEG_STREAM_TYPE] = XDF_Data[EEG_STREAM_TYPE][TIME_STREAM_TYPE][-1]\n",
    "\n",
    "start_times[EYE_STREAM_TYPE] = XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][0]\n",
    "end_times[EYE_STREAM_TYPE] = XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][-1]\n",
    "\n",
    "start_times[MARKER_STREAM_TYPE] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][0]\n",
    "end_times[MARKER_STREAM_TYPE] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][-1]\n",
    "\n",
    "start_times[\"Calibration\"] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][marker_indexes[PSYCHO_PY_MARKERS[\"calibrationStart\"]]]\n",
    "end_times[\"Calibration\"] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][marker_indexes[PSYCHO_PY_MARKERS[\"calibrationStop\"]]]\n",
    "\n",
    "start_times[\"Memorization\"] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][marker_indexes[PSYCHO_PY_MARKERS[\"memorizationStart\"]]]\n",
    "end_times[\"Memorization\"] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][marker_indexes[PSYCHO_PY_MARKERS[\"memorizationStop\"]]]\n",
    "\n",
    "start_times[\"Instruction\"] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][marker_indexes[PSYCHO_PY_MARKERS[\"instructionStart\"]]]\n",
    "end_times[\"Instruction\"] = XDF_Data[MARKER_STREAM_TYPE][TIME_STREAM_TYPE][marker_indexes[PSYCHO_PY_MARKERS[\"instructionStop\"]]]\n",
    "\n",
    "\n",
    "#plt.plot([start_times[EEG_STREAM_TYPE], end_times[EEG_STREAM_TYPE]], [0,0], label=\"EEG time\")\n",
    "plt.plot([start_times[EYE_STREAM_TYPE], end_times[EYE_STREAM_TYPE]], [1,1], label=\"EYE time\")\n",
    "plt.plot([start_times[MARKER_STREAM_TYPE], end_times[MARKER_STREAM_TYPE]], [2,2], label=\"MARKER time\")\n",
    "plt.plot([start_times[\"Calibration\"], end_times[\"Calibration\"]], [1.7,1.7], label=\"calibration time\")\n",
    "plt.plot([start_times[\"Memorization\"], end_times[\"Memorization\"]], [1.7,1.7], label=\"memorization time\")\n",
    "plt.plot([start_times[\"Instruction\"], end_times[\"Instruction\"]], [1.8,1.8], label=\"instruction time\")\n",
    "\n",
    "\n",
    "\n",
    "plt.ylim((-2, 4))\n",
    "plt.title(\"Data Times\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Sampling for Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Checks for Eye Sampling\n",
    "time_differences_eye_tracker = [XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][i+1]-XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][i] for i in range(len(XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE])-1)]\n",
    "mean_fs_eye_tracker = 1/np.mean(time_differences_eye_tracker)\n",
    "std_fs_eye_tracker = np.std(time_differences_eye_tracker)\n",
    "num_samples_eye_tracker = len(XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE])\n",
    "\n",
    "print(\"Max time difference of eye tracker:\\t\\t\\t\\t\", max(time_differences_eye_tracker))\n",
    "print(\"Min time difference of eye tracker:\\t\\t\\t\\t\", min(time_differences_eye_tracker))\n",
    "print(\"Avg time difference of eye tracker:\\t\\t\\t\\t\", np.mean(time_differences_eye_tracker))\n",
    "\n",
    "print(\"Mean eye sampling frequency (should be 30-50Hz):\\t\\t\", mean_fs_eye_tracker)\n",
    "print(\"Number of eye samples (should be >7000 for a full 5 min run):\\t\", num_samples_eye_tracker)\n",
    "\n",
    "\n",
    "# Visualize EEG recording gaps\n",
    "plt.plot(list(range(len(time_differences_eye_tracker))), time_differences_eye_tracker)\n",
    "plt.title(\"Time differences for Eye tracker\")\n",
    "plt.xlabel(\"ith time difference\")\n",
    "plt.ylabel(\"time difference value (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Inspect largest eye data pause: \n",
    "len_range = 50\n",
    "index_of_max_time_differences_eye_tracker = time_differences_eye_tracker.index(max(time_differences_eye_tracker))\n",
    "# print(\"Time differences around Max diff:\", time_differences_eeg[index_of_max_time_differences_eeg-len_range:index_of_max_time_differences_eeg+25])\n",
    "\n",
    "\n",
    "new_data = epochByTime(XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][index_of_max_time_differences_eye_tracker - len_range], XDF_Data[EYE_STREAM_TYPE][TIME_STREAM_TYPE][index_of_max_time_differences_eye_tracker + len_range], XDF_Data)\n",
    "print(\"Markers around largest time difference (--PsychopyStart is reasonable):\", new_data[StreamType.MARKER.value][StreamType.DATA.value])\n",
    "\n",
    "plt.plot(np.array(list(range(len(time_differences_eye_tracker[index_of_max_time_differences_eye_tracker-len_range:index_of_max_time_differences_eye_tracker+len_range])))) - len_range, time_differences_eye_tracker[index_of_max_time_differences_eye_tracker-len_range:index_of_max_time_differences_eye_tracker+len_range])\n",
    "plt.title(\"+/-\" + str(len_range)+ \" time differences around max diff index\")\n",
    "plt.ylabel(\"time difference value (s)\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Sampling for EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check EEG data times\n",
    "\n",
    "time_differences_eeg = [XDF_Data[EEG_STREAM_TYPE][TIME_STREAM_TYPE][i+1]-XDF_Data[EEG_STREAM_TYPE][TIME_STREAM_TYPE][i] for i in range(len(XDF_Data[EEG_STREAM_TYPE][TIME_STREAM_TYPE])-1)]\n",
    "mean_fs_eeg = 1/np.mean(time_differences_eeg)\n",
    "num_samples_eeg = len(XDF_Data[EEG_STREAM_TYPE][TIME_STREAM_TYPE])\n",
    "\n",
    "\n",
    "print(\"Max time difference of eeg (0.15 - 0.5 is reasonable):\\t\", max(time_differences_eeg))\n",
    "print(\"Min time difference of eeg (0.0001 is reasonable):\\t\", min(time_differences_eeg))\n",
    "print(\"Avg time difference of eeg (should be ~0.004):\\t\\t\", np.mean(time_differences_eeg))\n",
    "\n",
    "\n",
    "print(\"Mean eye sampling frequency (should be 250Hz):\\t\\t\", mean_fs_eeg)\n",
    "print(\"Number of eeg samples (should be 75,000 for a full 5 min run):\\t\", num_samples_eeg)\n",
    "\n",
    "# Visualize EEG recording gaps\n",
    "plt.plot(list(range(len(time_differences_eeg))), time_differences_eeg)\n",
    "plt.title(\"Time differences for EEG\")\n",
    "plt.xlabel(\"ith time difference\")\n",
    "plt.ylabel(\"time difference value (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Inspect largest EEG data pause: \n",
    "len_range = 50\n",
    "index_of_max_time_differences_eeg = time_differences_eeg.index(max(time_differences_eeg))\n",
    "# print(\"Time differences around Max diff:\", time_differences_eeg[index_of_max_time_differences_eeg-len_range:index_of_max_time_differences_eeg+25])\n",
    "\n",
    "\n",
    "new_data = epochByTime(XDF_Data[EEG_STREAM_TYPE][TIME_STREAM_TYPE][index_of_max_time_differences_eeg - len_range], XDF_Data[EEG_STREAM_TYPE][TIME_STREAM_TYPE][index_of_max_time_differences_eeg + len_range], XDF_Data)\n",
    "print(\"Markers around largest time difference (--PsychopyStart is reasonable):\", new_data[StreamType.MARKER.value][StreamType.DATA.value])\n",
    "\n",
    "plt.plot(np.array(list(range(len(time_differences_eeg[index_of_max_time_differences_eeg-len_range:index_of_max_time_differences_eeg+len_range])))) - len_range, time_differences_eeg[index_of_max_time_differences_eeg-len_range:index_of_max_time_differences_eeg+len_range])\n",
    "plt.title(\"+/-\" + str(len_range)+ \" time differences around max diff index\")\n",
    "plt.ylabel(\"time difference value (s)\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data for Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check eye data\n",
    "\n",
    "eye_x_data=XDF_Data[StreamType.EYENORM.value][StreamType.DATA.value][:,0]\n",
    "eye_y_data=XDF_Data[StreamType.EYENORM.value][StreamType.DATA.value][:,1]\n",
    "eye_time_data=XDF_Data[StreamType.EYENORM.value][StreamType.TIME.value]\n",
    "\n",
    "calibration_data = getSectionData(\"calibration\", XDF_Data)\n",
    "eye_x_data_calibration=calibration_data[StreamType.EYENORM.value][StreamType.DATA.value][:,0]\n",
    "eye_y_data_calibration=calibration_data[StreamType.EYENORM.value][StreamType.DATA.value][:,1]\n",
    "eye_time_data_calibration=calibration_data[StreamType.EYENORM.value][StreamType.TIME.value]\n",
    "\n",
    "\n",
    "N = 5\n",
    "smoothed_eye_x_data = np.convolve(eye_x_data, np.ones((N,))/N, mode='valid')\n",
    "smoothed_eye_y_data = np.convolve(eye_y_data, np.ones((N,))/N, mode='valid')\n",
    "smoothed_eye_x_calibration_data = np.convolve(eye_x_data_calibration, np.ones((N,))/N, mode='valid')\n",
    "\n",
    "f_hi = 2\n",
    "filtered_eye_x_data = filterEYE(eye_x_data, fs=eye_fs, f_hi=2)\n",
    "filtered_eye_y_data = filterEYE(eye_y_data, fs=eye_fs, f_hi=2)\n",
    "filtered_eye_x_calibration_data = filterEYE(eye_x_data_calibration, fs=eye_fs, f_hi=2)\n",
    "\n",
    "\n",
    "plt.plot(eye_time_data, eye_x_data, label=\"raw x data\")\n",
    "plt.plot(eye_time_data_calibration, eye_x_data_calibration, label=\"raw x cal data\")\n",
    "plt.title(\"raw eye x data\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(eye_time_data[N-1:], smoothed_eye_x_data, label=\"smooth x data\")\n",
    "plt.plot(eye_time_data_calibration[N-1:], smoothed_eye_x_calibration_data, label=\"smoothed x cal data\")\n",
    "plt.title(\"smooth eye x data\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(eye_time_data, filtered_eye_x_data, label=\"filtered x data\")\n",
    "plt.plot(eye_time_data_calibration, filtered_eye_x_calibration_data, label=\"filtered x cal data\")\n",
    "plt.title(\"filtered eye x data\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calibration processing of eye blinks and summary sanity checks\n",
    "calibrated_x = {}\n",
    "calibrated_y = {}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "ax1.set_title(\"right\")\n",
    "ax2.set_title(\"left\")\n",
    "fig.suptitle(\"Eye Tracker Graphs - X\")\n",
    "\n",
    "fig2, (ay1, ay2) = plt.subplots(1, 2, sharey=True)\n",
    "ay1.set_title(\"up\")\n",
    "ay2.set_title(\"down\")\n",
    "ay1.invert_yaxis() \n",
    "fig2.suptitle(\"Eye Tracker Graphs - Y\")\n",
    "\n",
    "\n",
    "# Smoothing for eye data (cut off frequency)\n",
    "f_hi = 2\n",
    "\n",
    "for x_dir in PSYCHOPY_DIRECTIONS_X.keys():\n",
    "    for y_dir in PSYCHOPY_DIRECTIONS_Y.keys(): \n",
    "        location = \"(\"+str(PSYCHOPY_DIRECTIONS_X[x_dir])+\", \"+str(PSYCHOPY_DIRECTIONS_Y[y_dir])+\")\"\n",
    "        new_data = epochByMarkIndex(marker_indexes[location] - 2, marker_indexes[location], XDF_Data)\n",
    "        x = new_data[EYE_NORM_STREAM_TYPE]['data'][:,0]\n",
    "        x = filterEYE(x, eye_fs, f_hi=f_hi)\n",
    "        new_data[EYE_NORM_STREAM_TYPE]['data'][:,0] = x\n",
    "        y = new_data[EYE_NORM_STREAM_TYPE]['data'][:,1]\n",
    "        y = filterEYE(y, eye_fs, f_hi=f_hi)\n",
    "        new_data[EYE_NORM_STREAM_TYPE]['data'][:,1] = y\n",
    "        time = new_data[EYE_NORM_STREAM_TYPE]['time']\n",
    "        timepoints=range(len(time))\n",
    "        if(x_dir == 'right') :\n",
    "            ax1.plot(x, timepoints, color=\"orange\")\n",
    "        if(x_dir == 'left') :\n",
    "            ax2.plot(x, timepoints, color=\"orange\")\n",
    "        \n",
    "        if(y_dir == 'up') :\n",
    "            ay1.plot(timepoints, y, color=\"orange\")\n",
    "        if(y_dir == 'down') :\n",
    "            ay2.plot(timepoints, y, color=\"orange\")\n",
    "        \n",
    "        # Get only the last 1/3 of time data from x\n",
    "        time_range = time[-1] - time[0]\n",
    "        time_range = time_range*2 / 3\n",
    "        start_time = time[0] + time_range\n",
    "        end_time = time[-1]\n",
    "        \n",
    "        third_data = epochByTime(start_time, end_time, new_data)\n",
    "        x = third_data[EYE_NORM_STREAM_TYPE]['data'][:,0]\n",
    "        y = third_data[EYE_NORM_STREAM_TYPE]['data'][:,1]\n",
    "        time_third = third_data[EYE_NORM_STREAM_TYPE]['time']\n",
    "        timepoints = np.array(list(range(len(time_third)))) + len(time) - len(time_third)\n",
    "        if(x_dir == 'right') :\n",
    "            ax1.plot(x, timepoints, color=\"blue\")\n",
    "        if(x_dir == 'left') :\n",
    "            ax2.plot(x, timepoints, color=\"blue\")\n",
    "            \n",
    "        if(y_dir == 'up') :\n",
    "            ay1.plot(timepoints, y, color=\"blue\")\n",
    "        if(y_dir == 'down') :\n",
    "            ay2.plot(timepoints, y, color=\"blue\")\n",
    "        \n",
    "        \n",
    "        # Append new average to calibration matricies\n",
    "        avg_x = np.mean(x)\n",
    "        avg_y = np.mean(y)\n",
    "        \n",
    "        if x_dir not in calibrated_x: \n",
    "            calibrated_x[x_dir] = list()\n",
    "        if y_dir not in calibrated_y: \n",
    "            calibrated_y[y_dir] = list()\n",
    "        calibrated_x[x_dir].append(avg_x)\n",
    "        calibrated_y[y_dir].append(avg_y)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# Average the eye locations\n",
    "avg_calibrated_x = {}\n",
    "avg_calibrated_y = {}\n",
    "for x_dir in calibrated_x: \n",
    "    avg_calibrated_x[x_dir] = np.mean(calibrated_x[x_dir])\n",
    "for y_dir in calibrated_y:\n",
    "    avg_calibrated_y[y_dir] = np.mean(calibrated_y[y_dir])\n",
    "    \n",
    "# Plot the eye averages\n",
    "for x_dir in avg_calibrated_x: \n",
    "    x = avg_calibrated_x[x_dir]\n",
    "    y = avg_calibrated_y['center']\n",
    "    plt.scatter([x], [y], label=x_dir)\n",
    "    plt.annotate(\n",
    "        x_dir,\n",
    "        xy=(x+0.01, y-0.005))\n",
    "for y_dir in avg_calibrated_y:\n",
    "    x = avg_calibrated_x['center']\n",
    "    y = avg_calibrated_y[y_dir]\n",
    "    plt.scatter([x], [y], label=y_dir)\n",
    "    plt.annotate(\n",
    "        y_dir,\n",
    "        xy=(x+0.01, y-0.005))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Location of eyes\");\n",
    "plt.show()\n",
    "\n",
    "# Summary \n",
    "x_eye_tracker_pass = False\n",
    "y_eye_tracker_pass = False\n",
    "if (avg_calibrated_x['center'] - avg_calibrated_x['left'] > 0) and (avg_calibrated_x['right'] - avg_calibrated_x['center'] > 0):\n",
    "    x_eye_tracker_pass = True\n",
    "\n",
    "if (avg_calibrated_y['center'] - avg_calibrated_y['up'] > 0) and (avg_calibrated_y['down'] - avg_calibrated_y['center'] > 0):\n",
    "    y_eye_tracker_pass = True\n",
    "    \n",
    "print(\"x_eye_tracker_pass:\", x_eye_tracker_pass)\n",
    "print(\"y_eye_tracker_pass:\", y_eye_tracker_pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meme showing eye movements vs Points. \n",
    "Looking Right should predict when they look at the meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_shown_data, a, b = getLabelBoundSingleLabelData(\"memeShown\", \"memeHidden\", XDF_Data, go_backward=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_shown_data, a, b = getTimeBoundSingleLabelData(\"newMeme\", XDF_Data, time_before=1, time_after=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_x_data=XDF_Data[StreamType.EYENORM.value][StreamType.DATA.value][:,0]\n",
    "eye_y_data=XDF_Data[StreamType.EYENORM.value][StreamType.DATA.value][:,1] + 2\n",
    "eye_time_data=XDF_Data[StreamType.EYENORM.value][StreamType.TIME.value]\n",
    "\n",
    "plt.plot(eye_time_data[len(eye_time_data)//2:], eye_x_data[len(eye_time_data)//2:], label=\"raw eye x data\")\n",
    "plt.plot(eye_time_data[len(eye_time_data)//2:], eye_y_data[len(eye_time_data)//2:], label=\"raw eye y data\")\n",
    "\n",
    "\n",
    "x_threshold_center_right = avg_calibrated_x['right']\n",
    "N=1\n",
    "smoothed_eye_x_data = np.convolve(eye_x_data, np.ones((N,))/N, mode='valid')\n",
    "looking_right = [-0 if val > x_threshold_center_right else -1 for i, val in enumerate(smoothed_eye_x_data)]\n",
    "plt.plot(eye_time_data[len(eye_time_data)//2+N-1:], looking_right[len(eye_time_data)//2:], label=\"predicted eye movement\")\n",
    "\n",
    "\n",
    "for i in range(len(meme_shown_data)): \n",
    "    eye_x_data=meme_shown_data[i][StreamType.EYENORM.value][StreamType.DATA.value][:,0]\n",
    "    eye_y_data=meme_shown_data[i][StreamType.EYENORM.value][StreamType.DATA.value][:,1] + 2\n",
    "    eye_time_data=meme_shown_data[i][StreamType.EYENORM.value][StreamType.TIME.value]\n",
    "\n",
    "    plt.plot(eye_time_data, eye_x_data)\n",
    "    plt.plot(eye_time_data, eye_y_data)\n",
    "\n",
    "\n",
    "data, time = getPointsAfterEachWord(XDF_Data)\n",
    "plt.plot(time[len(time)//3:], data[len(time)//3:], label=\"Point values\")\n",
    "plt.title(\"Eye tracker and point values\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Blink-related Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "new_data, a, b = getMarkerBoundSingleMarkerData(blinkText, \"--SpacePressed\", original_data=XDF_Data)\n",
    "blink_data=new_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check eye tracker\n",
    "eye_norm_data_x = blink_data[EYE_NORM_STREAM_TYPE]['data'][:,0]\n",
    "eye_norm_data_y = blink_data[EYE_NORM_STREAM_TYPE]['data'][:,1]\n",
    "eye_norm_data_time = blink_data[EYE_NORM_STREAM_TYPE]['time']\n",
    "\n",
    "plt.annotate(\n",
    "    \"start\",\n",
    "    xy=(eye_norm_data_x[0]+0.01, eye_norm_data_y[0] + 0.005))\n",
    "plt.annotate(\n",
    "    \"stop\",\n",
    "    xy=(eye_norm_data_x[-1]+0.01, eye_norm_data_y[-1] + 0.005))\n",
    "plt.plot(eye_norm_data_x, eye_norm_data_y)\n",
    "plt.title(\"x vs y\")\n",
    "plt.show()\n",
    "\n",
    "plt.annotate(\n",
    "    \"down\",\n",
    "    xy=(eye_norm_data_time[0]+0.01, max(eye_norm_data_y)-0.005))\n",
    "plt.annotate(\n",
    "    \"up\",\n",
    "    xy=(eye_norm_data_time[0]+0.01, min(eye_norm_data_y)+0.005))\n",
    "\n",
    "plt.plot(eye_norm_data_time, eye_norm_data_y)\n",
    "plt.title(\"Eye tracker norm of y component of 2 eye blinks\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "plt.annotate(\n",
    "    \"right\",\n",
    "    xy=(eye_norm_data_time[0]+0.01, max(eye_norm_data_x)-0.005))\n",
    "plt.annotate(\n",
    "    \"left\",\n",
    "    xy=(eye_norm_data_time[0]+0.01, min(eye_norm_data_x)+0.005))\n",
    "\n",
    "\n",
    "plt.plot(eye_norm_data_time, eye_norm_data_x)\n",
    "plt.title(\"Eye tracker norm of x component of 2 eye blinks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check EEG\n",
    "veog_eeg = blink_data[EEG_STREAM_TYPE]['data'][:,channels['VEOG']]\n",
    "heog_eeg = blink_data[EEG_STREAM_TYPE]['data'][:,channels['HEOG']]\n",
    "left_eeg = blink_data[EEG_STREAM_TYPE]['data'][:,channels['left_eeg']]\n",
    "right_eeg = blink_data[EEG_STREAM_TYPE]['data'][:,channels['right_eeg']]\n",
    "active_eeg = blink_data[EEG_STREAM_TYPE]['data'][:,list(channels.values())]\n",
    "eeg_time = blink_data[EEG_STREAM_TYPE]['time']\n",
    "\n",
    "\n",
    "# EEG eye blink data\n",
    "line_objects = plt.plot(eeg_time, active_eeg)\n",
    "plt.legend(iter(line_objects), list(channels.keys()))\n",
    "plt.title(\"EEG of 2 Eye Blinks\")\n",
    "plt.show()\n",
    "\n",
    "ica = FastICA(n_components=4)\n",
    "standardized=active_eeg\n",
    "standardized /= active_eeg.std(axis=0)\n",
    "S = ica.fit_transform(active_eeg)  # Reconstruct signals\n",
    "A = ica.mixing_\n",
    "line_objects = plt.plot(eeg_time, S)\n",
    "plt.legend(iter(line_objects), list(range(len(line_objects))))\n",
    "plt.title(\"ICA Decomposition of EEG of 2 Eye Blinks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG Filtering and Frequency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check All Data\n",
    "channel = channels['right_eeg']\n",
    "eeg_data=XDF_Data[StreamType.EEG.value][StreamType.DATA.value][:,channel]\n",
    "sig_filt = filterEEG(eeg_data, eeg_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eeg_data)\n",
    "plt.title(\"Raw EEG Signal for one electrode\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(sig_filt)\n",
    "plt.title(\"Filtered EEG Signal for one electrode\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the 60Hz data\n",
    "margin =  600 #len(freq) // 2 means all. 600 to see 60Hz\n",
    "\n",
    "freq, psd = signal.periodogram(eeg_data, fs=int(eeg_fs), scaling='spectrum')\n",
    "psd_mean = np.average(psd, axis = 0)\n",
    "#print(psd_mean)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD') # not sure what the unit is...\n",
    "plt.title('Raw PSD for one electrode')\n",
    "plt.plot(freq[len(freq) // 2 - margin : len(freq) // 2 + margin], psd[len(freq) // 2 - margin : len(freq) // 2 + margin])\n",
    "plt.show()\n",
    "\n",
    "freq, psd = signal.periodogram(sig_filt, fs=int(eeg_fs), scaling='spectrum')\n",
    "psd_mean = np.average(psd, axis = 0)\n",
    "#print(psd_mean)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD') # not sure what the unit is...\n",
    "plt.title('Filtered PSD for one electrode')\n",
    "plt.plot(freq[len(freq) // 2 - margin : len(freq) // 2 + margin], psd[len(freq) // 2 - margin : len(freq) // 2 + margin])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the 1-40hz data\n",
    "freq_mean, psd_mean = spectral.compute_spectrum(sig_filt, eeg_fs, method='welch', avg_type='mean', nperseg=eeg_fs*2)\n",
    "plt.title(\"Brain frequency PSD\")\n",
    "plt.xlabel(\"freq (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.plot(freq_mean[:len(freq_mean)//3], psd_mean[:len(freq_mean)//3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Eye Close Data\n",
    "new_data, a, b = getMarkerBoundSingleMarkerData(closeEyeText, \"--SpacePressed\", original_data=XDF_Data)\n",
    "close_eye_data = new_data[0]\n",
    "eeg_data=close_eye_data[StreamType.EEG.value][StreamType.DATA.value][400:,channel]\n",
    "time_data=close_eye_data[StreamType.EEG.value][StreamType.TIME.value][400:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_filt = filterEEG(eeg_data, eeg_fs)\n",
    "\n",
    "plt.plot(time_data, sig_filt)\n",
    "plt.title(\"Filtered EEG Signal for one electrode\")\n",
    "plt.xlabel(\"timestamp (s)\")\n",
    "plt.ylabel(\"Voltage (uV)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "alpha_range=(9, 11)\n",
    "# Compute instaneous amplitude from a signal\n",
    "amp = amp_by_time(sig_filt, eeg_fs, alpha_range)\n",
    "plt.plot(time_data, amp)\n",
    "plt.title(\"Alpha amp by time\")\n",
    "plt.xlabel(\"timestamp (s)\")\n",
    "plt.ylabel(\"amp\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "freq_mean, psd_mean = spectral.compute_spectrum(sig_filt, eeg_fs, method='welch', avg_type='mean', nperseg=eeg_fs*2)\n",
    "plt.title(\"Brain frequency PSD\")\n",
    "plt.xlabel(\"freq (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.plot(freq_mean[:len(freq_mean)//3], psd_mean[:len(freq_mean)//3])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Instructions Reading Data\n",
    "instruction_data = getSectionData(\"instruction\", XDF_Data)\n",
    "eeg_data=instruction_data[StreamType.EEG.value][StreamType.DATA.value][100:600,channel]\n",
    "sig_filt = filterEEG(eeg_data, eeg_fs)\n",
    "\n",
    "plt.plot(sig_filt)\n",
    "plt.title(\"Filtered EEG Signal for one electrode\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "freq_mean, psd_mean = spectral.compute_spectrum(sig_filt, eeg_fs, method='welch', avg_type='mean', nperseg=eeg_fs*2)\n",
    "plt.title(\"Brain frequency PSD\")\n",
    "plt.xlabel(\"freq (Hz)\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.plot(freq_mean[:len(freq_mean)//3], psd_mean[:len(freq_mean)//3])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
