{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MyND Offline Processing: Data Analysis\n",
    "Author: Geeling Chau<br> \n",
    "Description: Process xdf files recorded from experimental sessions to determine file eligibility and data feature extraction.<br>\n",
    "Sources: \n",
    "- Ollie's Segment Speller Offline Processing Code https://github.com/ollie-d/SegSpeller/blob/master/Offline%20Processing.ipynb \n",
    "- neurodsp https://github.com/neurodsp-tools/neurodsp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- [X] standard error bars\n",
    "- [x] reaction time analysis\n",
    "- [ ] word length analysis\n",
    "- [X] Psychopy adjust difficulty \n",
    "- [X] flash memes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helperFunctions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-36c1ab292a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelperFunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataAnalysisFunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helperFunctions'"
     ]
    }
   ],
   "source": [
    "from helperFunctions import *\n",
    "from constants import *\n",
    "from dataAnalysisFunctions import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neurodsp.timefrequency import amp_by_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = (8, 12)\n",
    "theta = (4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_marker_string = getLabelMarkerString(\"newWord\")\n",
    "end_marker_string = getLabelMarkerString(\"endWord\")\n",
    "target_word_string = getSingleLabelMarkerString(\"targetWord\")\n",
    "space_pressed_string = getSingleLabelMarkerString(\"spacePressed\")\n",
    "response_start_string = getSectionMarkerString(\"response\")[0] # Get the 0th element to get the start string\n",
    "space_pressed_string = getLabelMarkerString(\"spacePressed\")\n",
    "letters_shown_string = getLabelMarkerString(\"lettersShown\")\n",
    "meme_shown_string = getLabelMarkerString(\"memeShown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_shown_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAmpByTimeLeftRight(data_frame, eeg_fs, band, cutoff_timepoints) :\n",
    "    amp_rights = list()\n",
    "    amp_lefts = list() \n",
    "\n",
    "    for i, row in data_frame.iterrows(): \n",
    "        sig_right = row[\"data\"][StreamType.EEG.value][StreamType.DATA.value][:, channels[\"right_eeg\"]][:cutoff_timepoints]\n",
    "        amp_right = amp_by_time(sig_right, eeg_fs, band)\n",
    "        amp_rights.append(amp_right[~np.isnan(amp_right)])\n",
    "\n",
    "        sig_left = row[\"data\"][StreamType.EEG.value][StreamType.DATA.value][:, channels[\"left_eeg\"]][:cutoff_timepoints]\n",
    "        amp_left = amp_by_time(sig_left, eeg_fs, band)\n",
    "        amp_lefts.append(amp_left[~np.isnan(amp_left)])\n",
    "        \n",
    "    return amp_lefts, amp_rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrials(data):\n",
    "    data_list, a, t_data = getLabelBoundSingleLabelData(\"newWord\", \"endWord\", data, go_backward=False)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReactionTime(data) :\n",
    "    markers = data[StreamType.MARKER.value][StreamType.DATA.value]\n",
    "    times = data[StreamType.MARKER.value][StreamType.TIME.value]\n",
    "    if (PSYCHO_PY_MARKERS[\"spacePressed\"] in markers) and (PSYCHO_PY_MARKERS[\"spacePressed\"] in markers): \n",
    "        \n",
    "        index_space = np.where(data[StreamType.MARKER.value][StreamType.DATA.value] == PSYCHO_PY_MARKERS[\"spacePressed\"])[0]\n",
    "        index_start = np.where(data[StreamType.MARKER.value][StreamType.DATA.value] == PSYCHO_PY_MARKERS[\"newWord\"])[0]\n",
    "        \n",
    "        return (times[index_space] - times[index_start])[0]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReactionTimes(data_list) :\n",
    "\n",
    "    reaction_times = list()\n",
    "    for data in data_list: \n",
    "        reaction_times.append(getReactionTime(data))\n",
    "    \n",
    "    return reaction_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareDFs(dfs, names, band=alpha, eeg_fs=250, cutoff_timepoints=250):\n",
    "    counter=0\n",
    "    for df in dfs:  \n",
    "        print(names[counter]+\" len:\" ,  len(df))\n",
    "        counter+=1\n",
    "    \n",
    "    amp_lefts=list()\n",
    "    amp_rights=list()\n",
    "    amp_avg=list()\n",
    "    amp_diff=list()\n",
    "    sem_avgs = list()\n",
    "    sem_diffs = list()\n",
    "    \n",
    "    for df in dfs: \n",
    "        amp_lefts1, amp_rights1 = getAmpByTimeLeftRight(df, eeg_fs=eeg_fs, band=band, cutoff_timepoints=cutoff_timepoints)\n",
    "        amp_lefts.append(amp_lefts1)\n",
    "        amp_rights.append(amp_rights1)\n",
    "        \n",
    "        avg_list_sub = list()\n",
    "        diff_list_sub = list()\n",
    "        for i in range(len(amp_lefts1)) :\n",
    "            avg_list_sub.append(np.mean([amp_lefts1[i], amp_rights1[i]], axis=0))\n",
    "            diff_list_sub.append(amp_lefts1[i] - amp_rights1[i])\n",
    "        amp_avg.append(avg_list_sub)\n",
    "        amp_diff.append(diff_list_sub)\n",
    "        \n",
    "        sem_avgs.append(sp.stats.sem(avg_list_sub,axis=0))\n",
    "        sem_diffs.append(sp.stats.sem(diff_list_sub,axis=0))\n",
    "        \n",
    "    \n",
    "    # Average amp by time Alpha\n",
    "    for i in range(len(amp_avg)) : \n",
    "        av = np.nanmean(amp_avg[i], axis=0)\n",
    "        plt.plot(av, label=names[i])\n",
    "        plt.fill_between(list(range(len(av))), av-sem_avgs[i], av+sem_avgs[i], alpha = 0.2)\n",
    "\n",
    "    plt.title(\"Average amp by time\")\n",
    "    plt.ylabel(\"power of band\")\n",
    "    plt.xlabel(\"timepoints from start of word\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#     # Diff amp by time Alpha\n",
    "#     for i in range(len(amp_lefts)) : \n",
    "#         dif = np.nanmean(amp_diff[i], axis=0)\n",
    "#         plt.plot(dif, label=names[i])\n",
    "#         plt.fill_between(list(range(len(dif))), dif-sem_diffs[i], dif+sem_diffs[i], alpha = 0.2)\n",
    "        \n",
    "#     plt.title(\"Diff amp by time\")\n",
    "#     plt.ylabel(\"power of band\")\n",
    "#     plt.xlabel(\"timepoints from start of word\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSmoothedPerformance(original_performance, num_ahead=1, num_behind=1): \n",
    "    # num_ahead: the number of elements to check ahead of this element\n",
    "    # num_behind: the number of elements to check behind this element\n",
    "    to_return = list()\n",
    "    for i in range(len(original_performance)):\n",
    "        value = False\n",
    "        for j in range(1, num_ahead+1):\n",
    "            if i >= j: \n",
    "                if original_performance[i-j]: \n",
    "                    value = True\n",
    "                    break\n",
    "        for j in range(1, num_behind+1):\n",
    "            if i < len(original_performance) - j:\n",
    "                if original_performance[i+j]: \n",
    "                    value = True\n",
    "                    break\n",
    "        if original_performance[i]:\n",
    "            to_return.append(True)\n",
    "        else : \n",
    "            to_return.append(value)\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Files that work with this notebook: \n",
    "participant_P004_exp001_block_full_start.xdf # full start\n",
    "participant_P004_exp002_block_full_start.xdf # This should work: after restarting computer\n",
    "participant_P004_exp003_block_full_start.xdf # This should work too\n",
    "participant_P004_exp001_block_full_short.xdf # Works\n",
    "participant_P004_exp001_block_full_long.xdf # Works\n",
    "\n",
    "participant_P001_exp001_block_full_long.xdf # Me, very sleepy. \n",
    "\n",
    "P001/participant_P001_exp001_block_long.xdf \n",
    "P001/participant_P001_exp001_block_short.xdf # Meme shown markers are wonky \n",
    "P001/participant_P001_exp001_block_start.xdf # before changing the point system on the \"m\" press\n",
    "\n",
    "participant_P001_exp001_block_test_markers.xdf # Meme shown markers should be fixed\n",
    "\n",
    "P005/participant_P005_exp001_block_start.xdf # \n",
    "P005/participant_P005_exp001_block_short.xdf # \n",
    "P005/participant_P005_exp001_block_long.xdf # Full set with new markers and point system\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "XDF_Data = loadxdf(\"../data/P001/participant_P001_exp001_block_long.xdf\")\n",
    "if StreamType.EEG.value in XDF_Data :\n",
    "    eeg_fs = getEEGfs(XDF_Data)\n",
    "    print(\"eeg_fs = \", eeg_fs)\n",
    "if StreamType.EYE.value in XDF_Data : \n",
    "    eye_fs = getEYEfs(XDF_Data) \n",
    "    print(\"eye_fs = \", eye_fs)\n",
    "# Trim the data to only include the time PsychoPy was running\n",
    "XDF_Data = epochByMarkIndex(0, -1, XDF_Data)\n",
    "\n",
    "marker_indexes = getMarkerIndexes(XDF_Data)\n",
    "\n",
    "# Recording data checks (whether all markers are there etc)\n",
    "markersFound = True\n",
    "for marker_key in PSYCHO_PY_MARKERS : \n",
    "    if PSYCHO_PY_MARKERS[marker_key] not in marker_indexes.keys(): \n",
    "        markersFound = False \n",
    "        print(\"Missing Marker:\", PSYCHO_PY_MARKERS[marker_key])\n",
    "print(\"All Markers Found?\", markersFound)\n",
    "    \n",
    "print(\"\\n\\ncheck calibration markers:\\n\\n\",XDF_Data[StreamType.MARKER.value][StreamType.DATA.value][:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter 1-50 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = filterStreamStructEEG(XDF_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check filtering\n",
    "for channel in channels: \n",
    "    eeg_data = XDF_Data[StreamType.EEG.value][StreamType.DATA.value][:,channels[channel]]\n",
    "    plt.plot(eeg_data)\n",
    "plt.title(\"Raw EEG Data\")\n",
    "plt.show()\n",
    "\n",
    "for channel in channels: \n",
    "    eeg_data = filtered_data[StreamType.EEG.value][StreamType.DATA.value][:,channels[channel]]\n",
    "    plt.plot(eeg_data)\n",
    "plt.title(\"EEG Data filtered to \" + str(f_range))\n",
    "margin =  800 #len(freq) // 2 means all. 600 to see 60Hz\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, psd = signal.periodogram(filtered_data[StreamType.EEG.value][StreamType.DATA.value][:,channels[\"right_eeg\"]], fs=int(eeg_fs), scaling='spectrum')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('PSD') # not sure what the unit is...\n",
    "plt.title('Filtered PSD for one electrode 60Hz should be mostly attenuated)')\n",
    "plt.semilogy(freq[: int(len(freq) / 1.5)], psd[: int(len(freq) / 1.5)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean artifacts from VEOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Filter the entire EEG data\n",
    "\n",
    "# Show original blink data\n",
    "new_data, a, b = getMarkerBoundSingleMarkerData(blinkText, \"--SpacePressed\", original_data=filtered_data)\n",
    "blink_data=new_data[0]\n",
    "\n",
    "line_objects = plt.plot(blink_data[StreamType.EEG.value][StreamType.TIME.value], blink_data[StreamType.EEG.value][StreamType.DATA.value][:,list(channels.values())])\n",
    "plt.legend(iter(line_objects), list(channels.keys()))\n",
    "plt.title(\"filtered EEG of Blink section with filtered blinks\")\n",
    "plt.show()\n",
    "\n",
    "#Filter the entire EEG data\n",
    "filtered_cleaned_data  = getCleanedSignal(filtered_data, verbose=False)\n",
    "\n",
    "\n",
    "# Show the cleaned data at the blink section\n",
    "new_data, a, b = getMarkerBoundSingleMarkerData(blinkText, \"--SpacePressed\", original_data=filtered_cleaned_data)\n",
    "blink_data = new_data[0]\n",
    "\n",
    "line_objects = plt.plot(blink_data[StreamType.EEG.value][StreamType.TIME.value], blink_data[StreamType.EEG.value][StreamType.DATA.value][:,list(channels.values())])\n",
    "plt.legend(iter(line_objects), list(channels.keys()))\n",
    "plt.title(\"filtered EEG of Blink section with filtered and blinks removed\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get points for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sections\n",
    "numSections = getNumSections(filtered_cleaned_data)\n",
    "article_sections = list()\n",
    "for i in range(numSections) : \n",
    "    article_sections.append(getArticleSectionData(\"response\", i, filtered_cleaned_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, article_section in enumerate(article_sections):\n",
    "    data, time = getPointsAfterEachWord(article_section)\n",
    "    num_delta_points = getTotalPoints(article_section)\n",
    "    plt.plot(time[:], data[:], label=\"section \" + str(i) + \": \" + str(num_delta_points) + \" points\")\n",
    "plt.title(\"point values\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get meme show and hide times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_is_shown_data, a, b = getLabelBoundSingleLabelData(\"memeShown\", \"memeHidden\", filtered_cleaned_data, go_backward=False)\n",
    "if len(meme_is_shown_data) == 0: \n",
    "    articles_with_memes = list()\n",
    "    articles_without_memes = list() \n",
    "    for section in article_sections:\n",
    "        if meme_shown_string in section[StreamType.MARKER.value][StreamType.DATA.value] :\n",
    "            articles_with_memes.append(section)\n",
    "        else : \n",
    "            articles_without_memes.append(section)\n",
    "    meme_is_shown_data = articles_with_memes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the time frames in which the memes are shown\n",
    "# meme_is_shown_data, a, b = getLabelBoundSingleLabelData(\"memeShown\", \"memeHidden\", filtered_cleaned_data, go_backward=False)\n",
    "meme_shown_times = list() \n",
    "for data in meme_is_shown_data:\n",
    "    start_time = data[StreamType.MARKER.value][StreamType.TIME.value][0]\n",
    "    end_time = data[StreamType.MARKER.value][StreamType.TIME.value][-1]\n",
    "    meme_shown_times.append((start_time, end_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finer Epoching\n",
    "Target vs Nontarget <br> \n",
    "SpacePressed vs NoSpacePressed <br> \n",
    "Meme vs No Meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct data frame \n",
    "\n",
    "# This version doesn't work because we need to know when the neew article starts. \n",
    "# new_word_data, a, t_data = getLabelBoundSingleLabelData(\"newWord\", \"endWord\", filtered_cleaned_data, go_backward=False)\n",
    "# points = [getTotalPoints(data) for data in new_word_data] \n",
    "\n",
    "\n",
    "new_word_data, a, t_data = getTimeBoundSingleLabelData(\"newWord\", filtered_cleaned_data, time_before=0.5, time_after=1.5)\n",
    "points = [getTotalPoints(data) for data in new_word_data] \n",
    "\n",
    "data_info = dict() \n",
    "data_info[\"data_index\"] = list() \n",
    "data_info[\"data\"] = list() \n",
    "data_info[\"is_target\"] = list() \n",
    "data_info[\"is_pressed\"] = list()\n",
    "data_info[\"has_letters_shown\"] = list() \n",
    "data_info[\"has_meme\"] = list() \n",
    "data_info[\"time\"] = list() \n",
    "data_info[\"points\"] = list() \n",
    "data_info[\"reaction_time\"] = list() \n",
    "data_info[\"section_number\"] = list()\n",
    "\n",
    "\n",
    "section_number = 0\n",
    "\n",
    "end_times = list()\n",
    "for i, point in enumerate(points):\n",
    "    if(response_start_string in new_word_data[i][StreamType.MARKER.value][StreamType.DATA.value]) : \n",
    "        section_number += 1\n",
    "    \n",
    "    # Find this word's start and end indexes \n",
    "    marker_indexes = getMarkerIndexes(new_word_data[i])\n",
    "    start_word_index = marker_indexes[start_marker_string][0]\n",
    "    end_word_index = marker_indexes[end_marker_string][-1]\n",
    "    end_time = float(new_word_data[i][StreamType.MARKER.value][StreamType.TIME.value][end_word_index])\n",
    "    end_times.append(end_time)\n",
    "    # Determine if meme was shown\n",
    "    has_meme = False\n",
    "    for meme_shown_interval in meme_shown_times: \n",
    "        if (end_time > meme_shown_interval[0] and end_time < meme_shown_interval[1]) :\n",
    "            has_meme = True\n",
    "            break\n",
    "\n",
    "    # Determine if word is a target word\n",
    "    is_target = False\n",
    "    if target_word_string in new_word_data[i][StreamType.MARKER.value][StreamType.DATA.value][start_word_index:end_word_index] : \n",
    "        is_target = True\n",
    "    \n",
    "    # Determine if word was pressed on \n",
    "    is_pressed = False\n",
    "    if space_pressed_string in new_word_data[i][StreamType.MARKER.value][StreamType.DATA.value][start_word_index:end_word_index] : \n",
    "        is_pressed = True\n",
    "        \n",
    "    # Determine if word had letters shown\n",
    "    has_letters_shown = False\n",
    "    if letters_shown_string in new_word_data[i][StreamType.MARKER.value][StreamType.DATA.value][start_word_index:end_word_index] : \n",
    "        has_letters_shown = True\n",
    "    \n",
    "    # Get reaction time\n",
    "    data_list = getTrials(new_word_data[i])\n",
    "    this_data = data_list[0]\n",
    "    reaction_time = getReactionTime(this_data)\n",
    "    \n",
    "    \n",
    "    data_info[\"data_index\"].append(i)\n",
    "    data_info[\"data\"].append(new_word_data[i])\n",
    "    data_info[\"is_target\"].append(is_target)\n",
    "    data_info[\"is_pressed\"].append(is_pressed)\n",
    "    data_info[\"has_letters_shown\"].append(has_letters_shown)\n",
    "    data_info[\"has_meme\"].append(has_meme)\n",
    "    data_info[\"time\"].append(t_data[i])\n",
    "    data_info[\"points\"].append(point)\n",
    "    data_info[\"section_number\"].append(section_number)\n",
    "    data_info[\"reaction_time\"].append(reaction_time)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"has_meme\"], label=\"has meme\")\n",
    "plt.plot(df[\"reaction_time\"], label=\"reaction times\")\n",
    "plt.xlabel(\"trial\")\n",
    "plt.ylabel(\"1 = 1 sec or has meme. 0 = no response or no meme.\")\n",
    "plt.title(\"reaction time vs meme shown\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"This shows if there's any correlation between showing the memes and a elongation of reaction time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"is_target\"], label=\"target word\")\n",
    "plt.plot([ 0 if (i > 0) and (df[\"section_number\"][i-1] != df[\"section_number\"][i]) else 1 for i, row in df.iterrows()], label=\"article change\")\n",
    "plt.title(\"Target Word times and the article changes\")\n",
    "plt.xlabel(\"trial\")\n",
    "plt.ylabel(\"1 = target word, 0 = not target word\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"This shows the distribution of target words shown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfocused_state = getSmoothedPerformance((df[\"is_pressed\"] == False) & (df[\"is_target\"] == True), 10, 3)\n",
    "unfocused_df = df[unfocused_state]\n",
    "focused_df = df[np.logical_not(unfocused_state)]\n",
    "print(\"alpha\")\n",
    "compareDFs([ unfocused_df, focused_df],[ \"unfocused\", \"focused\"], band=alpha )\n",
    "print(\"theta\")\n",
    "compareDFs([ unfocused_df, focused_df],[ \"unfocused\", \"focused\"], band=theta )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_df = df[(df[\"is_pressed\"] == True) & (df[\"is_target\"] == True)] \n",
    "missed_df = df[(df[\"is_pressed\"] == False) & (df[\"is_target\"] == True)] \n",
    "print(\"alpha\")\n",
    "compareDFs([df, correct_df, missed_df],[\"all\", \"correct\", \"missed\"], band=alpha )\n",
    "print(\"theta\")\n",
    "compareDFs([df, correct_df, missed_df],[\"all\", \"correct\", \"missed\"], band=theta )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_react_df = df[(df[\"is_pressed\"] == True) & (df[\"is_target\"] == True) & (df[\"reaction_time\"] > 0.6)] \n",
    "fast_react_df = df[(df[\"is_pressed\"] == True) & (df[\"is_target\"] == True) & (df[\"reaction_time\"] < 0.6)] \n",
    "print(\"alpha\")\n",
    "compareDFs([df, slow_react_df, fast_react_df],[\"all\", \"slow\", \"fast\"], band=alpha )\n",
    "print(\"theta\")\n",
    "compareDFs([df, slow_react_df, fast_react_df],[\"all\", \"slow\", \"fast\"], band=theta )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_df = df[(df[\"has_meme\"] == True)]\n",
    "nomeme_df = df[(df[\"has_meme\"] == False)]\n",
    "print(\"alpha\")\n",
    "compareDFs([df, meme_df, nomeme_df],[\"all\", \"meme\", \"nomeme\"], band=alpha )\n",
    "print(\"theta\")\n",
    "compareDFs([df, meme_df, nomeme_df],[\"all\", \"meme\", \"nomeme\"], band=theta )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = df[(df[\"points\"] < 0)]\n",
    "good_df = df[(df[\"points\"] > 0)]\n",
    "print(\"alpha\")\n",
    "compareDFs([df, error_df, good_df],[\"all\", \"error\", \"good\"], band=alpha )\n",
    "print(\"theta\")\n",
    "compareDFs([df, error_df, good_df],[\"all\", \"error\", \"good\"], band=theta )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooof import FOOOF, FOOOFGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEEGFromDataFrame_AvgLeftRight(df):\n",
    "    eeg_list = list()\n",
    "    for i, row in df.iterrows():\n",
    "        data = row[\"data\"]\n",
    "        left_eeg = data[StreamType.EEG.value][StreamType.DATA.value][:,channels['left_eeg']]\n",
    "        right_eeg = data[StreamType.EEG.value][StreamType.DATA.value][:,channels['right_eeg']]\n",
    "        avg_eeg = np.mean([left_eeg, right_eeg], axis=0)\n",
    "        eeg_list.append(avg_eeg)\n",
    "    return eeg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEEGFromDataList_AvgLeftRight(data_list):\n",
    "    eeg_list = list() \n",
    "    for data in data_list: \n",
    "        left_eeg = data[StreamType.EEG.value][StreamType.DATA.value][:,channels['left_eeg']]\n",
    "        right_eeg = data[StreamType.EEG.value][StreamType.DATA.value][:,channels['right_eeg']]\n",
    "        avg_eeg = np.mean([left_eeg, right_eeg], axis=0)\n",
    "        eeg_list.append(avg_eeg)\n",
    "    return eeg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from calibration phase\n",
    "# May need to change this depending on the dataset and the available markers. \n",
    "# Older datasets may not have the start and end markers that are helpful for directly getting the section data. \n",
    "# Older datasets may also have different identifying text. \n",
    "data_open_eyes, index, index_sub = getMarkerBoundSingleMarkerData('Try not to blink, look at the center of your screen, and count to 5\\n\\nthen Press Space', '--SpacePressed',  filtered_cleaned_data, go_backward=True)\n",
    "data_relax, index, index_sub = getMarkerBoundSingleMarkerData('Relax for at least 5 seconds\\n\\nthen Press Space', '--SpacePressed',  filtered_cleaned_data, go_backward=True)\n",
    "data_close_eyes, index, index_sub = getMarkerBoundSingleMarkerData('Close your eyes and count to 5\\n\\nthen Press Space', '--SpacePressed',  filtered_cleaned_data, go_backward=True)\n",
    "\n",
    "data_list = [data_open_eyes[0], data_relax[0], data_close_eyes[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_list = getEEGFromDataList_AvgLeftRight(data_list)\n",
    "fits = getFOOOFFits(eeg_list, (1,40))\n",
    "fits[1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits[2].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_left = filtered_cleaned_data[StreamType.EEG.value][StreamType.DATA.value][:,channels['left_eeg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_right = filtered_cleaned_data[StreamType.EEG.value][StreamType.DATA.value][:,channels['right_eeg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.mean([all_left, all_right], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = getFOOOFFits([avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfocused_eeg = getEEGFromDataFrame_AvgLeftRight(unfocused_df)\n",
    "len(unfocused_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unfocused_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits = getFOOOFFits(unfocused_eeg, freq_range=(7, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits[3].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_params = getPeakParams(fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = getCFs(peak_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = {'verbose':False}\n",
    "def getFOOOFFits(eeg_list, freq_range=(2, 20)):\n",
    "    fits = list()\n",
    "    for eeg in eeg_list:\n",
    "        freqs, psd = spectral.compute_spectrum(eeg, eeg_fs, method='welch', avg_type='median', nperseg=eeg_fs)\n",
    "        f = FOOOF(**sets) \n",
    "        f.fit(freqs, psd, freq_range)\n",
    "        fits.append(f)\n",
    "    return fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPeakParams(fooof_fits):\n",
    "    return [f.peak_params_ for f in fooof_fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCFs(peak_params_list):\n",
    "    return [getCF(p) for pp in peak_params_list for p in pp]\n",
    "def getAmps(peak_params_list):\n",
    "    return [getAmp(p) for pp in peak_params_list for p in pp]\n",
    "def getBWs(peak_params_list):\n",
    "    return [getBW(p) for pp in peak_params_list for p in pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCF(peak_data):\n",
    "    if peak_data is None:\n",
    "        return 0\n",
    "    return peak_data[0]\n",
    "\n",
    "def getAmp(peak_data):\n",
    "    if peak_data is None:\n",
    "        return 0 \n",
    "    return peak_data[1]\n",
    "\n",
    "def getBW(peak_data):\n",
    "    if peak_data is None:\n",
    "        return 0 \n",
    "    return peak_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = meme_df[\"data\"].values\n",
    "eeg_list = [data[StreamType.EEG.value][StreamType.DATA.value][:,channels[\"left_eeg\"]] for data in datas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=(6, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fooof_fits = getFOOOFFits(eeg_list, freq=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_params = [f.peak_params_ for f in fooof_fits]\n",
    "errors = [f.error_ for f in fooof_fits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(errors[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fooof_fits[4].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fooof_fits[0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = [getCF(p) for pp in peak_params for p in pp]\n",
    "amp = [getAmp(p) for pp in peak_params for p in pp]\n",
    "bw = [getBW(p) for pp in peak_params for p in pp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(peak_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfocused_df = df[((df[\"is_pressed\"] == False) & (df[\"is_target\"] == True))]\n",
    "unfocused_data = unfocused_df[\"data\"].values\n",
    "unfocused_windows = getWindowsList(unfocused_df)\n",
    "unfocused_freqs, unfocused_psds, unfocused_psd_avg = getFreqsAndPSD(unfocused_windows) \n",
    "unfocused_power_ratio = [getPowerRatio(data[:499], binning) for data in unfocused_windows]\n",
    "\n",
    "unfocused_sem = getSEM(unfocused_power_ratio)\n",
    "unfocused_power_ratio_avg = np.mean(unfocused_power_ratio, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "focused_df = df[((df[\"is_pressed\"] == True) & (df[\"is_target\"] == True))]\n",
    "focused_data = focused_df[\"data\"].values\n",
    "focused_windows = getWindowsList(focused_df)\n",
    "focused_freqs, focused_psds, focused_psd_avg = getFreqsAndPSD(focused_windows) \n",
    "focused_power_ratio = [getPowerRatio(data[:499], binning) for data in focused_windows]\n",
    "\n",
    "focused_sem = getSEM(focused_power_ratio)\n",
    "focused_power_ratio_avg = np.mean(focused_power_ratio, axis=0)\n",
    "\n",
    "\n",
    "super_focused_df = df[((df[\"is_pressed\"] == True) & (df[\"is_target\"] == True) & (df[\"has_meme\"] == True))]\n",
    "super_focused_data = super_focused_df[\"data\"].values\n",
    "super_focused_windows = getWindowsList(super_focused_df)\n",
    "super_focused_freqs, super_focused_psds, super_focused_psd_avg = getFreqsAndPSD(super_focused_windows) \n",
    "super_focused_power_ratio = [getPowerRatio(data[:499], binning) for data in super_focused_windows]\n",
    "\n",
    "super_focused_sem = getSEM(super_focused_power_ratio)\n",
    "super_focused_power_ratio_avg = np.mean(super_focused_power_ratio, axis=0)\n",
    "\n",
    "\n",
    "super_unfocused_df = df[((df[\"is_pressed\"] == False) & (df[\"is_target\"] == True) & (df[\"has_meme\"] == True))]\n",
    "super_unfocused_data = super_unfocused_df[\"data\"].values\n",
    "super_unfocused_windows = getWindowsList(super_unfocused_df)\n",
    "super_unfocused_freqs, super_unfocused_psds, super_unfocused_psd_avg = getFreqsAndPSD(super_unfocused_windows) \n",
    "super_unfocused_power_ratio = [getPowerRatio(data[:499], binning) for data in super_unfocused_windows]\n",
    "\n",
    "super_unfocused_sem = getSEM(super_unfocused_power_ratio)\n",
    "super_unfocused_power_ratio_avg = np.mean(super_unfocused_power_ratio, axis=0)\n",
    "\n",
    "\n",
    "mispress_df = df[((df[\"is_pressed\"] == True) & (df[\"is_target\"] == False))]\n",
    "mispress_data = mispress_df[\"data\"].values\n",
    "mispress_windows = getWindowsList(mispress_df)\n",
    "mispress_freqs, mispress_psds, mispress_psd_avg = getFreqsAndPSD(mispress_windows) \n",
    "mispress_power_ratio = [getPowerRatio(data[:499], binning) for data in mispress_windows]\n",
    "\n",
    "mispress_sem = getSEM(mispress_power_ratio)\n",
    "mispress_power_ratio_avg = np.mean(mispress_power_ratio, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
